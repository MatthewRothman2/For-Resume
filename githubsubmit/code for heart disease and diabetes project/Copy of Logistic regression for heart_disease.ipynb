{"cells":[{"cell_type":"code","source":["import pandas as _hex_pandas\n","import datetime as _hex_datetime\n","import json as _hex_json"],"execution_count":null,"metadata":{"id":"vsdclMbycJts"},"outputs":[]},{"cell_type":"code","source":["hex_scheduled = _hex_json.loads(\"false\")"],"outputs":[],"execution_count":null,"metadata":{"id":"jNr6jS5lcJtt"}},{"cell_type":"code","source":["hex_user_email = _hex_json.loads(\"\\\"example-user@example.com\\\"\")"],"outputs":[],"execution_count":null,"metadata":{"id":"OLMGbNT5cJtu"}},{"cell_type":"code","source":["hex_user_attributes = _hex_json.loads(\"{}\")"],"outputs":[],"execution_count":null,"metadata":{"id":"95TOKw0kcJtu"}},{"cell_type":"code","source":["hex_run_context = _hex_json.loads(\"\\\"logic\\\"\")"],"outputs":[],"execution_count":null,"metadata":{"id":"j7LjjunxcJtu"}},{"cell_type":"code","source":["hex_timezone = _hex_json.loads(\"\\\"UTC\\\"\")"],"outputs":[],"execution_count":null,"metadata":{"id":"MBs_GBy7cJtu"}},{"cell_type":"code","source":["hex_project_id = _hex_json.loads(\"\\\"0f71f051-16c2-4835-862f-50b2f22b95e5\\\"\")"],"outputs":[],"execution_count":null,"metadata":{"id":"4CrkH-v0cJtu"}},{"cell_type":"code","source":["hex_project_name = _hex_json.loads(\"\\\"Logistic regression for heart_disease\\\"\")"],"outputs":[],"execution_count":null,"metadata":{"id":"8tNTYDW2cJtv"}},{"cell_type":"code","source":["hex_status = _hex_json.loads(\"\\\"\\\"\")"],"outputs":[],"execution_count":null,"metadata":{"id":"oW-qpQqicJtv"}},{"cell_type":"code","source":["hex_categories = _hex_json.loads(\"[]\")"],"outputs":[],"execution_count":null,"metadata":{"id":"evZu8DydcJtv"}},{"cell_type":"code","source":["hex_color_palette = _hex_json.loads(\"[\\\"#4C78A8\\\",\\\"#F58518\\\",\\\"#E45756\\\",\\\"#72B7B2\\\",\\\"#54A24B\\\",\\\"#EECA3B\\\",\\\"#B279A2\\\",\\\"#FF9DA6\\\",\\\"#9D755D\\\",\\\"#BAB0AC\\\"]\")"],"outputs":[],"execution_count":null,"metadata":{"id":"UKoFJq7xcJtv"}},{"cell_type":"code","source":["# import jinja2\n","# raw_query = \"\"\"\n","#     select * from \"heart_diseases.csv\";\n","# \"\"\"\n","# sql_query = jinja2.Template(raw_query).render(vars())"],"metadata":{"id":"LOC4dYPrcJtv"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["# import jinja2\n","# raw_query = \"\"\"\n","#     SELECT\n","#         ca,\n","#         id,\n","#         age,\n","#         fbs,\n","#         chol,\n","#         \"CK-MB\",\n","#         exang,\n","#         thalch,\n","#         oldpeak,\n","#         \"Troponin\",\n","#         \"sex_Male\",\n","#         trestbps,\n","#         \"Heart rate\",\n","#         \"sex_Female\",\n","#         slope_flat,\n","#         \"Blood sugar\",\n","#         thal_normal,\n","#         restecg_normal,\n","#         cp_asymptomatic,\n","#         \"dataset_Hungary\",\n","#         slope_upsloping,\n","#         \"cp_typical angina\",\n","#         \"dataset_Cleveland\",\n","#         slope_downsloping,\n","#         \"thal_fixed defect\",\n","#         \"cp_atypical angina\",\n","#         \"dataset_VA Long Beach\",\n","#         \"restecg_lv hypertrophy\",\n","#         \"thal_reversable defect\",\n","#         \"Systolic blood pressure\",\n","#         \"Diastolic blood pressure\",\n","#         \"restecg_st-t abnormality\",\n","#         num\n","#     FROM heart_diseases;\n","# \"\"\"\n","# sql_query = jinja2.Template(raw_query).render(vars())"],"metadata":{"id":"YxsIFLeUcJtw"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import ConfusionMatrixDisplay\n","\n","# Define features and target variable\n","drop_columns = [\"id\", \"num\"]\n","X = dataframe.drop(columns=drop_columns)\n","y = dataframe[\"num\"]\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n",")\n","\n","# Initialize and train the logistic regression model\n","logreg = LogisticRegression(max_iter=1000, solver=\"liblinear\")\n","logreg.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred = logreg.predict(X_test)\n","# Make predictions on the training set\n","train_pred = logreg.predict(X_train)\n","\n","# Calculate accuracy, precision, and recall for test set\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred)\n","recall = recall_score(y_test, y_pred)\n","\n","# Calculate accuracy, precision, and recall for training set\n","train_accuracy = accuracy_score(y_train, train_pred)\n","train_precision = precision_score(y_train, train_pred)\n","train_recall = recall_score(y_train, train_pred)\n","# Print accuracy, precision, and recall\n","# Print test metrics\n","print(f\"Test Accuracy: {accuracy}\")\n","print(f\"Test Precision: {precision}\")\n","print(f\"Test Recall: {recall}\")\n","\n","# Print train metrics\n","print(f\"Train Accuracy: {train_accuracy}\")\n","print(f\"Train Precision: {train_precision}\")\n","print(f\"Train Recall: {train_recall}\")\n","\n","# Display the confusion matrix\n","from sklearn.metrics import confusion_matrix\n","\n","cm = confusion_matrix(y_test, y_pred)\n","print(\"Confusion Matrix:\")\n","print(cm)"],"metadata":{"id":"-8sdb8T5cJtw","outputId":"c0918f8a-ee22-4a5e-eef8-4ff21db9d78a"},"execution_count":null,"outputs":[{"data":{"text/plain":"Test Accuracy: 0.85\nTest Precision: 0.8333333333333334\nTest Recall: 0.8\nTrain Accuracy: 0.8661087866108786\nTrain Precision: 0.8867924528301887\nTrain Recall: 0.8245614035087719\nConfusion Matrix:\n[[31  4]\n [ 5 20]]\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":["\n","\n","from sklearn.linear_model import LogisticRegression\n","import numpy as np\n","\n","# Fit the logistic regression model\n","logreg = LogisticRegression(max_iter=10000)\n","logreg.fit(X_train, y_train)\n","\n","# Get feature importance\n","feature_importance = np.abs(logreg.coef_[0])\n","\n","# Create a DataFrame for feature importance\n","feature_importance_df = pd.DataFrame(\n","    {\"Feature\": X_train.columns, \"Importance\": feature_importance}\n",")\n","feature_importance_df = feature_importance_df.sort_values(\n","    by=\"Importance\", ascending=False\n",")\n","\n","feature_importance_df"],"metadata":{"id":"y7fl0I_ycJtw","outputId":"868432a2-5bd5-4d77-a65c-4a08961d4d82"},"execution_count":null,"outputs":[{"data":{"application/vnd.hex.export+parquet":{"success":true,"exportKey":"0ce08258-fbec-40a6-b70e-6bec71b8ae88/0f71f051-16c2-4835-862f-50b2f22b95e5/exports/1a0d9d47-c7c2-4b09-8c3c-a6c67d51be3b"},"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Feature</th>\n      <th>Importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>17</th>\n      <td>cp_asymptomatic</td>\n      <td>1.570013</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>ca</td>\n      <td>1.194466</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>exang</td>\n      <td>0.939263</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>sex_Female</td>\n      <td>0.776005</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>sex_Male</td>\n      <td>0.711762</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>cp_atypical angina</td>\n      <td>0.679973</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>slope_flat</td>\n      <td>0.487842</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>fbs</td>\n      <td>0.477249</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>slope_upsloping</td>\n      <td>0.460500</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>oldpeak</td>\n      <td>0.433221</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>cp_typical angina</td>\n      <td>0.397216</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>thal_reversable defect</td>\n      <td>0.396924</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>thal_normal</td>\n      <td>0.392065</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>restecg_normal</td>\n      <td>0.211987</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>dataset_Cleveland</td>\n      <td>0.210183</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>dataset_VA Long Beach</td>\n      <td>0.137437</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>restecg_lv hypertrophy</td>\n      <td>0.113156</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>slope_downsloping</td>\n      <td>0.091586</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>thal_fixed defect</td>\n      <td>0.069104</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Troponin</td>\n      <td>0.046683</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>restecg_st-t abnormality</td>\n      <td>0.034587</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Diastolic blood pressure</td>\n      <td>0.028334</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Systolic blood pressure</td>\n      <td>0.023858</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>trestbps</td>\n      <td>0.023639</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>thalch</td>\n      <td>0.018623</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Heart rate</td>\n      <td>0.012884</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>age</td>\n      <td>0.009690</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>dataset_Hungary</td>\n      <td>0.008502</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Blood sugar</td>\n      <td>0.004044</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CK-MB</td>\n      <td>0.003770</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>chol</td>\n      <td>0.002610</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":["from sklearn.inspection import permutation_importance\n","import pandas as pd\n","\n","# Fit the logistic regression model\n","logreg = LogisticRegression(max_iter=10000)\n","logreg.fit(X_train, y_train)\n","\n","# Get feature importance\n","result = permutation_importance(logreg, X_test, y_test, n_repeats=10, random_state=0)\n","feature_importance = result.importances_mean\n","# Create a DataFrame for feature importance\n","# Create a DataFrame for feature importance and rename it to `feature_imp_df`\n","feature_imp_df = pd.DataFrame(\n","    {\"Feature\": X_test.columns, \"Importance\": feature_importance}\n",")\n","feature_imp_df = feature_importance_df.sort_values(by=\"Importance\", ascending=False)\n","\n","feature_imp_df"],"metadata":{"id":"Uf0eKTD1cJtw","outputId":"44c1341e-1fe3-4010-ee92-e2244eb656ed"},"execution_count":null,"outputs":[{"data":{"application/vnd.hex.export+parquet":{"success":true,"exportKey":"0ce08258-fbec-40a6-b70e-6bec71b8ae88/0f71f051-16c2-4835-862f-50b2f22b95e5/exports/f65e651f-e5ce-43c3-b5c2-04f8fc7107b4"},"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Feature</th>\n      <th>Importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>17</th>\n      <td>cp_asymptomatic</td>\n      <td>1.570013</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>ca</td>\n      <td>1.194466</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>exang</td>\n      <td>0.939263</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>sex_Female</td>\n      <td>0.776005</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>sex_Male</td>\n      <td>0.711762</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>cp_atypical angina</td>\n      <td>0.679973</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>slope_flat</td>\n      <td>0.487842</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>fbs</td>\n      <td>0.477249</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>slope_upsloping</td>\n      <td>0.460500</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>oldpeak</td>\n      <td>0.433221</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>cp_typical angina</td>\n      <td>0.397216</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>thal_reversable defect</td>\n      <td>0.396924</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>thal_normal</td>\n      <td>0.392065</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>restecg_normal</td>\n      <td>0.211987</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>dataset_Cleveland</td>\n      <td>0.210183</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>dataset_VA Long Beach</td>\n      <td>0.137437</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>restecg_lv hypertrophy</td>\n      <td>0.113156</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>slope_downsloping</td>\n      <td>0.091586</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>thal_fixed defect</td>\n      <td>0.069104</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Troponin</td>\n      <td>0.046683</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>restecg_st-t abnormality</td>\n      <td>0.034587</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Diastolic blood pressure</td>\n      <td>0.028334</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Systolic blood pressure</td>\n      <td>0.023858</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>trestbps</td>\n      <td>0.023639</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>thalch</td>\n      <td>0.018623</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Heart rate</td>\n      <td>0.012884</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>age</td>\n      <td>0.009690</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>dataset_Hungary</td>\n      <td>0.008502</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Blood sugar</td>\n      <td>0.004044</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CK-MB</td>\n      <td>0.003770</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>chol</td>\n      <td>0.002610</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.metrics import ConfusionMatrixDisplay\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","\n","# Initialize lists to store metrics for each run\n","accuracy_list = []\n","precision_list = []\n","recall_list = []\n","\n","# Filter features with different importance thresholds and return the accuracy, precision, and recall for each threshold\n","# Filter features with importance greater than the specified threshold\n","threshold = 0.4\n","X_filtered = X[\n","    feature_importance_df[feature_importance_df[\"Importance\"] > threshold][\n","        \"Feature\"\n","    ].values.tolist()\n","]\n","print(\"Features used:\", X_filtered.columns.tolist())\n","# Define the parameter grid for hyperparameter tuning\n","param_grid = {\"C\": [1], \"penalty\": [\"l2\"], \"solver\": [\"liblinear\"]}\n","\n","# Initialize the logistic regression model\n","logreg = LogisticRegression()\n","\n","# Initialize GridSearchCV\n","grid_search = GridSearchCV(\n","    estimator=logreg, param_grid=param_grid, cv=5, scoring=\"accuracy\"\n",")\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X_filtered, y, test_size=0.2, random_state=42\n",")\n","\n","# Fit the model\n","grid_search.fit(X_train, y_train)\n","# Run the model 100 times\n","for _ in range(100):\n","    # Split the data into training and testing sets\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        X_filtered, y, test_size=0.2, random_state=np.random.randint(0, 10000)\n","    )\n","\n","    # Fit the model\n","    grid_search.fit(X_train, y_train)\n","\n","    # Make predictions on the test set\n","    y_pred = grid_search.predict(X_test)\n","\n","    # Calculate accuracy, precision, and recall\n","    accuracy = accuracy_score(y_test, y_pred)\n","    precision = precision_score(y_test, y_pred, average=\"binary\")\n","    recall = recall_score(y_test, y_pred, average=\"binary\")\n","\n","    # Append metrics to lists\n","    accuracy_list.append(accuracy)\n","    precision_list.append(precision)\n","    recall_list.append(recall)\n","\n","# Calculate average metrics\n","avg_accuracy = np.mean(accuracy_list)\n","avg_precision = np.mean(precision_list)\n","avg_recall = np.mean(recall_list)\n","\n","# Get the best parameters and best score\n","best_params = grid_search.best_params_\n","best_score = grid_search.best_score_\n","\n","# Make predictions on the test set\n","y_pred = grid_search.predict(X_test)\n","\n","# Calculate accuracy, precision, and recall\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred, average=\"binary\")\n","recall = recall_score(y_test, y_pred, average=\"binary\")\n","train_pred = grid_search.predict(X_train)\n","train_accuracy = accuracy_score(y_train, train_pred)\n","train_precision = precision_score(y_train, train_pred, average=\"binary\")\n","train_recall = recall_score(y_train, train_pred, average=\"binary\")\n","\n","# Calculate confusion matrix\n","cm = confusion_matrix(y_test, y_pred)\n","print(\"Confusion Matrix:\")\n","print(cm)\n","\n","# Store results\n","results = {\n","    \"best_params\": best_params,\n","    \"best_score\": best_score,\n","    \"test_accuracy\": avg_accuracy,\n","    \"test_precision\": avg_precision,\n","    \"test_recall\": avg_recall,\n","    \"train_accuracy\": train_accuracy,\n","    \"train_precision\": train_precision,\n","    \"train_recall\": train_recall,\n","}\n","\n","# Print results\n","print(\"Results:\")\n","print(\"Best parameters:\", results[\"best_params\"])\n","print(\"Best score:\", results[\"best_score\"])\n","print(\"Test accuracy:\", results[\"test_accuracy\"])\n","print(\"Test precision:\", results[\"test_precision\"])\n","print(\"Test recall:\", results[\"test_recall\"])\n","print(\"Train accuracy:\", results[\"train_accuracy\"])\n","print(\"Train precision:\", results[\"train_precision\"])\n","print(\"Train recall:\", results[\"train_recall\"])"],"metadata":{"id":"If_T7kOAcJtx","outputId":"9d9464ce-dd74-4b75-d9b8-dde006b3a5cf"},"execution_count":null,"outputs":[{"data":{"text/plain":"Features used: ['cp_asymptomatic', 'ca', 'exang', 'sex_Female', 'sex_Male', 'cp_atypical angina', 'slope_flat', 'fbs', 'slope_upsloping', 'oldpeak']\nConfusion Matrix:\n[[29  2]\n [ 6 23]]\nResults:\nBest parameters: {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\nBest score: 0.8325354609929076\nTest accuracy: 0.8255\nTest precision: 0.8304663395894023\nTest recall: 0.7847879064541428\nTrain accuracy: 0.8493723849372385\nTrain precision: 0.8303571428571429\nTrain recall: 0.8454545454545455\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":["from sklearn.model_selection import cross_val_score\n","from sklearn.linear_model import LogisticRegression\n","\n","# Filter features with importance above 0.05\n","important_features = feature_importance_df[feature_importance_df[\"Importance\"] > 0.05][\n","    \"Feature\"\n","].tolist()\n","X_filtered = X[important_features]\n","\n","# Initialize Logistic Regression model\n","logreg = LogisticRegression(max_iter=1000)\n","\n","# Perform cross-validation\n","cv_scores = cross_val_score(logreg, X_filtered, y, cv=5)\n","\n","# Print cross-validation scores\n","cv_scores"],"metadata":{"id":"5bnQL_E_cJtx","outputId":"c217804c-e250-4f1b-c3ea-c14fa2d2104e"},"execution_count":null,"outputs":[{"data":{"text/plain":"array([0.88333333, 0.9       , 0.8       , 0.86666667, 0.79661017])"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":["from sklearn.model_selection import GridSearchCV\n","\n","# Filter features with importance greater than 0.05\n","important_features = feature_importance_df[feature_importance_df[\"Importance\"] > 0.05][\n","    \"Feature\"\n","].tolist()\n","X_filtered = X[important_features]\n","\n","# Define the parameter grid for hyperparameter tuning\n","param_grid = {\n","    \"C\": [0.01, 0.1, 1, 10, 100, 1000],\n","    \"penalty\": [\"l1\", \"l2\"],\n","    \"solver\": [\"liblinear\", \"saga\"],\n","}\n","\n","# Initialize the logistic regression model\n","logreg = LogisticRegression()\n","\n","# Initialize GridSearchCV\n","grid_search = GridSearchCV(\n","    estimator=logreg, param_grid=param_grid, cv=5, scoring=\"accuracy\"\n",")\n","\n","# Fit the model\n","grid_search.fit(X_filtered, y)\n","\n","# Get the best parameters and best score\n","best_params = grid_search.best_params_\n","best_score = grid_search.best_score_\n","\n","best_params, best_score"],"metadata":{"id":"DUaR8ffpcJtx","outputId":"0d155b8d-66ab-47c3-e108-6b556dad0eeb"},"execution_count":null,"outputs":[{"data":{"text/plain":"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"},{"data":{"text/plain":"({'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}, 0.8493220338983051)"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import recall_score\n","\n","# Filter features with importance greater than 0.05\n","important_features = feature_importance_df[feature_importance_df[\"Importance\"] > 0.05][\n","    \"Feature\"\n","].tolist()\n","X_filtered = X[important_features]\n","\n","# Define the parameter grid for hyperparameter tuning\n","param_grid = {\n","    \"C\": [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n","    \"penalty\": [\"l1\", \"l2\", \"elasticnet\", \"none\"],\n","    \"solver\": [\"liblinear\", \"saga\"],\n","}\n","\n","# Initialize the logistic regression model\n","logreg = LogisticRegression()\n","\n","# Initialize GridSearchCV\n","grid_search = GridSearchCV(\n","    estimator=logreg, param_grid=param_grid, cv=5, scoring=\"recall\"\n",")\n","\n","# Fit the model\n","grid_search.fit(X_filtered, y)\n","\n","# Get the best parameters and best score\n","best_params = grid_search.best_params_\n","best_score = grid_search.best_score_\n","\n","best_params, best_score"],"metadata":{"id":"WJ-GQ1wrcJtx","outputId":"cbb15278-45d7-47ef-871b-68ecf603ba5e"},"execution_count":null,"outputs":[{"data":{"text/plain":"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n105 fits failed out of a total of 280.\nThe score on these train-test partitions for these parameters will be set to nan.\nIf these failures are not expected, you can try to debug them by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n35 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n    solver = _check_solver(self.solver, self.penalty, self.dual)\n  File \"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 64, in _check_solver\n    raise ValueError(\nValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n\n--------------------------------------------------------------------------------\n35 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n  File \"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n    return super().__call__(iterable_with_config)\n  File \"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/joblib/parallel.py\", line 1085, in __call__\n    if self.dispatch_one_batch(iterator):\n  File \"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/joblib/parallel.py\", line 819, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n    result = ImmediateResult(func)\n  File \"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n    self.results = batch()\n  File \"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/joblib/parallel.py\", line 288, in __call__\n    return [func(*args, **kwargs)\n  File \"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n    return self.function(*args, **kwargs)\n  File \"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 521, in _logistic_regression_path\n    alpha = (1.0 / C) * (1 - l1_ratio)\nTypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n\n--------------------------------------------------------------------------------\n35 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n    solver = _check_solver(self.solver, self.penalty, self.dual)\n  File \"/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 71, in _check_solver\n    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\nValueError: penalty='none' is not supported for the liblinear solver\n\n  warnings.warn(some_fits_failed_message, FitFailedWarning)\n/home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.9/lib/python3.9/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.         0.2        0.89126984 0.33042328        nan        nan\n        nan 0.79021164 0.         0.         0.83386243 0.73994709\n        nan        nan        nan 0.79021164 0.81984127 0.7547619\n 0.80502646 0.78333333        nan        nan        nan 0.79021164\n 0.8047619  0.7973545  0.8047619  0.8047619         nan        nan\n        nan 0.79021164 0.79021164 0.79021164 0.79021164 0.79021164\n        nan        nan        nan 0.79021164 0.79021164 0.79021164\n 0.79021164 0.79021164        nan        nan        nan 0.79021164\n 0.79021164 0.79021164 0.79021164 0.79021164        nan        nan\n        nan 0.79021164]\n  warnings.warn(\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"},{"data":{"text/plain":"({'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}, 0.8912698412698413)"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":[],"metadata":{"id":"EbbOlPJ_cJty"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import GridSearchCV\n","\n","# Filter features with different importance thresholds and return the accuracy, precision, and recall for each threshold\n","thresholds = [0.05]\n","important_features = []\n","for threshold in thresholds:\n","    features = feature_importance_df[feature_importance_df[\"Importance\"] > threshold][\n","        \"Feature\"\n","    ].tolist()\n","    important_features.extend(features)\n","important_features = list(set(important_features))  # Remove duplicates\n","\n","\n","# Define the parameter grid for hyperparameter tuning\n","param_grid = {\"C\": [1], \"penalty\": [\"l2\"], \"solver\": [\"liblinear\"]}\n","\n","# Initialize the logistic regression model\n","logreg = LogisticRegression()\n","\n","# Initialize GridSearchCV\n","grid_search = GridSearchCV(\n","    estimator=logreg, param_grid=param_grid, cv=5, scoring=\"accuracy\"\n",")\n","\n","# Initialize the logistic regression model\n","logreg = LogisticRegression()\n","\n","# Initialize GridSearchCV\n","grid_search = GridSearchCV(\n","    estimator=logreg, param_grid=param_grid, cv=5, scoring=\"accuracy\"\n",")\n","\n","# Dictionary to store results\n","results = {}\n","\n","# Iterate over thresholds\n","for threshold in thresholds:\n","    important_features = feature_importance_df[\n","        feature_importance_df[\"Importance\"] > threshold\n","    ][\"Feature\"].tolist()\n","    X_filtered = X[important_features]\n","\n","    # Fit the model\n","    grid_search.fit(X_filtered, y)\n","\n","    # Get the best parameters and best score\n","    best_params = grid_search.best_params_\n","    best_score = grid_search.best_score_\n","\n","    # Perform cross-validation\n","    cv_scores = cross_val_score(grid_search.best_estimator_, X_filtered, y, cv=5)\n","    precision_scores = cross_val_score(\n","        grid_search.best_estimator_, X_filtered, y, cv=5, scoring=\"precision\"\n","    )\n","    recall_scores = cross_val_score(\n","        grid_search.best_estimator_, X_filtered, y, cv=5, scoring=\"recall\"\n","    )\n","\n","    # Store results\n","    results[threshold] = {\n","        \"best_params\": best_params,\n","        \"best_score\": best_score,\n","        \"cv_scores\": cv_scores,\n","        \"precision_scores\": precision_scores,\n","        \"recall_scores\": recall_scores,\n","    }\n","\n","# Print results\n","for threshold, result in results.items():\n","    print(f\"Threshold: {threshold}\")\n","    print(\"Best parameters:\", result[\"best_params\"])\n","    print(\"Best score:\", result[\"best_score\"])\n","    print(\"Cross-validation scores:\", result[\"cv_scores\"])\n","    print(\"Cross-validation precision scores:\", result[\"precision_scores\"])\n","    print(\"Cross-validation recall scores:\", result[\"recall_scores\"])"],"metadata":{"id":"85zV74MtcJty","outputId":"ed0d79d9-6050-4313-a3c6-e7236960d24f"},"execution_count":null,"outputs":[{"data":{"text/plain":"Threshold: 0.05\nBest parameters: {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\nBest score: 0.8493220338983051\nCross-validation scores: [0.88333333 0.9        0.8        0.86666667 0.79661017]\nCross-validation precision scores: [0.95652174 0.89285714 0.76666667 0.85714286 0.85714286]\nCross-validation recall scores: [0.78571429 0.89285714 0.82142857 0.85714286 0.66666667]\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import (\n","    accuracy_score,\n","    precision_score,\n","    recall_score,\n","    ConfusionMatrixDisplay,\n",")\n","from sklearn.model_selection import GridSearchCV\n","\n","# Filter features with different importance thresholds and return the accuracy, precision, and recall for each threshold\n","thresholds = [0.05, 0.1, 0.2]\n","important_features = []\n","for threshold in thresholds:\n","    features = feature_importance_df[feature_importance_df[\"Importance\"] > threshold][\n","        \"Feature\"\n","    ].tolist()\n","    important_features.extend(features)\n","important_features = list(set(important_features))  # Remove duplicates\n","important_features = sorted(\n","    important_features,\n","    key=lambda x: feature_importance_df[feature_importance_df[\"Feature\"] == x][\n","        \"Importance\"\n","    ].values[0],\n","    reverse=True,\n",")[:3]\n","\n","param_grid = {\"C\": [0.1, 1, 10], \"penalty\": [\"l2\"], \"solver\": [\"liblinear\"]}\n","\n","# Initialize the logistic regression model\n","logreg = LogisticRegression()\n","\n","# Initialize GridSearchCV\n","grid_search = GridSearchCV(\n","    estimator=logreg, param_grid=param_grid, cv=5, scoring=\"accuracy\"\n",")\n","\n","\n","# Dictionary to store results\n","results = {}\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X_filtered, y, test_size=0.2, random_state=42\n",")\n","\n","# Fit the model using GridSearchCV\n","grid_search.fit(X_train, y_train)\n","# Predict on the training set\n","train_pred = grid_search.predict(X_train)\n","\n","# Predict on the test set\n","y_pred = grid_search.predict(X_test)\n","\n","# Calculate accuracy, precision, and recall for test set\n","test_accuracy = accuracy_score(y_test, y_pred)\n","test_precision = precision_score(y_test, y_pred)\n","test_recall = recall_score(y_test, y_pred)\n","\n","# Calculate accuracy, precision, and recall for training set\n","train_accuracy = accuracy_score(y_train, train_pred)\n","train_precision = precision_score(y_train, train_pred)\n","train_recall = recall_score(y_train, train_pred)\n","# Print the scores\n","print(f\"Train Accuracy: {train_accuracy}\")\n","print(f\"Train Precision: {train_precision}\")\n","print(f\"Train Recall: {train_recall}\")\n","print(f\"Test Accuracy: {test_accuracy}\")\n","print(f\"Test Precision: {test_precision}\")\n","print(f\"Test Recall: {test_recall}\")\n","\n","# Print the confusion matrix\n","ConfusionMatrixDisplay.from_estimator(grid_search, X_test, y_test)\n","plt.show()"],"metadata":{"id":"rPITaBC6cJty","outputId":"15c260dc-5e16-4284-98ab-90ed02883290"},"execution_count":null,"outputs":[{"data":{"text/plain":"Train Accuracy: 0.8410041841004184\nTrain Precision: 0.8392857142857143\nTrain Recall: 0.8245614035087719\nTest Accuracy: 0.8333333333333334\nTest Precision: 0.8260869565217391\nTest Recall: 0.76\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":["from sklearn.model_selection import GridSearchCV\n","\n","\n","# Define the parameter grid for hyperparameter tuning\n","param_grid = {\"C\": [1], \"penalty\": [\"l2\"], \"solver\": [\"liblinear\"]}\n","\n","# Initialize the logistic regression model\n","logreg = LogisticRegression()\n","\n","# Initialize GridSearchCV\n","grid_search = GridSearchCV(\n","    estimator=logreg, param_grid=param_grid, cv=5, scoring=\"accuracy\"\n",")\n","\n","# Fit the model\n","grid_search.fit(X, y)\n","\n","# Get the best parameters and best score\n","best_params = grid_search.best_params_\n","best_score = grid_search.best_score_\n","\n","print(\"Best parameters:\", best_params)\n","print(\"Best score:\", best_score)\n","\n","# Perform 5 iterations of cross-validation and print the results\n","cv_scores = cross_val_score(logreg, X_filtered, y, cv=5)\n","print(\"Cross-validation scores:\", cv_scores)\n","\n","# Calculate precision and recall for cross-validation\n","precision_scores = cross_val_score(logreg, X_filtered, y, cv=5, scoring=\"precision\")\n","recall_scores = cross_val_score(logreg, X_filtered, y, cv=5, scoring=\"recall\")\n","print(\"Cross-validation precision scores:\", precision_scores)\n","print(\"Cross-validation recall scores:\", recall_scores)"],"metadata":{"id":"OEa3pjXScJty","outputId":"27fe2b73-542c-4782-bd69-cbc8b1e9859a"},"execution_count":null,"outputs":[{"data":{"text/plain":"Best parameters: {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\nBest score: 0.8292090395480226\nCross-validation scores: [0.88333333 0.9        0.8        0.86666667 0.79661017]\nCross-validation precision scores: [0.95652174 0.89285714 0.76666667 0.85714286 0.85714286]\nCross-validation recall scores: [0.78571429 0.89285714 0.82142857 0.85714286 0.66666667]\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":[],"metadata":{"id":"j9DUOIL6cJty"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import ConfusionMatrixDisplay\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","\n","# Filter features with different importance thresholds and return the accuracy, precision, and recall for each threshold\n","thresholds = [0.05]\n","important_features = features\n","for threshold in thresholds:\n","    features = feature_importance_df[feature_importance_df[\"Importance\"] > threshold][\n","        \"Feature\"\n","    ].tolist()\n","\n","print(\"Features used:\", features)\n","\n","# Define the parameter grid for hyperparameter tuning\n","param_grid = {\"C\": 1, \"penalty\": \"l2\", \"solver\": \"liblinear\"}\n","\n","# Initialize the logistic regression model\n","logreg = LogisticRegression(**param_grid)\n","\n","# Dictionary to store results\n","results = {}\n","\n","# Iterate over thresholds\n","for threshold in thresholds:\n","    # Split the data into training and testing sets\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        X_filtered, y, test_size=0.2, random_state=42\n","    )\n","\n","    # Fit the model\n","    logreg.fit(X_train, y_train)\n","\n","    # Make predictions on the test set\n","    y_pred = logreg.predict(X_test)\n","\n","    # Calculate accuracy, precision, and recall\n","    accuracy = accuracy_score(y_test, y_pred)\n","    precision = precision_score(y_test, y_pred, average=\"binary\")\n","    recall = recall_score(y_test, y_pred, average=\"binary\")\n","    train_pred = logreg.predict(X_train)\n","    train_accuracy = accuracy_score(y_train, train_pred)\n","    train_precision = precision_score(y_train, train_pred, average=\"binary\")\n","    train_recall = recall_score(y_train, train_pred, average=\"binary\")\n","\n","    # Calculate confusion matrix\n","    cm = confusion_matrix(y_test, y_pred)\n","    print(\"Confusion Matrix:\")\n","    print(cm)\n","\n","    # Store results\n","    results[threshold] = {\n","        \"test_accuracy\": accuracy,\n","        \"test_precision\": precision,\n","        \"test_recall\": recall,\n","        \"train_accuracy\": train_accuracy,\n","        \"train_precision\": train_precision,\n","        \"train_recall\": train_recall,\n","    }\n","\n","# Print results\n","for threshold, result in results.items():\n","    print(f\"Threshold: {threshold}\")\n","    print(\"Test accuracy:\", result[\"test_accuracy\"])\n","    print(\"Test precision:\", result[\"test_precision\"])\n","    print(\"Test recall:\", result[\"test_recall\"])\n","    print(\"Train accuracy:\", result[\"train_accuracy\"])\n","    print(\"Train precision:\", result[\"train_precision\"])\n","    print(\"Train recall:\", result[\"train_recall\"])"],"metadata":{"id":"_hH5Go2UcJty","outputId":"f620d29a-e4a1-472c-d6d2-53ba3fb1944d"},"execution_count":null,"outputs":[{"data":{"text/plain":"Features used: ['cp_asymptomatic', 'ca', 'exang', 'sex_Female', 'sex_Male', 'cp_atypical angina', 'slope_flat', 'fbs', 'slope_upsloping', 'oldpeak', 'cp_typical angina', 'thal_reversable defect', 'thal_normal', 'restecg_normal', 'dataset_Cleveland', 'dataset_VA Long Beach', 'restecg_lv hypertrophy', 'slope_downsloping', 'thal_fixed defect']\nConfusion Matrix:\n[[30  5]\n [ 5 20]]\nThreshold: 0.05\nTest accuracy: 0.8333333333333334\nTest precision: 0.8\nTest recall: 0.8\nTrain accuracy: 0.8493723849372385\nTrain precision: 0.8611111111111112\nTrain recall: 0.8157894736842105\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":["from sklearn.metrics import ConfusionMatrixDisplay\n","\n","# Print the features used\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","\n","# Filter features with different importance thresholds and return the accuracy, precision, and recall for each threshold\n","\n","# Filter features with importance greater than 0.05\n","\n","X_filtered = X[\n","    feature_importance_df[feature_importance_df[\"Importance\"] > 0.40][\n","        \"Feature\"\n","    ].values.tolist()\n","]\n","print(\"Features used:\", X_filtered.columns.tolist())\n","# Define the parameter grid for hyperparameter tuning\n","param_grid = {\"C\": [1], \"penalty\": [\"l2\"], \"solver\": [\"liblinear\"]}\n","\n","# Initialize the logistic regression model\n","logreg = LogisticRegression()\n","\n","# Initialize GridSearchCV\n","grid_search = GridSearchCV(\n","    estimator=logreg, param_grid=param_grid, cv=5, scoring=\"accuracy\"\n",")\n","\n","# Dictionary to store results\n","results = {}\n","\n","# Iterate over thresholds\n","for threshold in thresholds:\n","    # Split the data into training and testing sets\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        X_filtered, y, test_size=0.2, random_state=42\n","    )\n","\n","    # Fit the model\n","    grid_search.fit(X_train, y_train)\n","\n","    # Get the best parameters and best score\n","    best_params = grid_search.best_params_\n","    best_score = grid_search.best_score_\n","\n","    # Make predictions on the test set\n","    y_pred = grid_search.predict(X_test)\n","\n","    # Calculate accuracy, precision, and recall\n","    accuracy = accuracy_score(y_test, y_pred)\n","    precision = precision_score(y_test, y_pred, average=\"binary\")\n","    recall = recall_score(y_test, y_pred, average=\"binary\")\n","    train_pred = grid_search.predict(X_train)\n","    train_accuracy = accuracy_score(y_train, train_pred)\n","    train_precision = precision_score(y_train, train_pred, average=\"binary\")\n","    train_recall = recall_score(y_train, train_pred, average=\"binary\")\n","\n","    # Calculate confusion matrix\n","    cm = confusion_matrix(y_test, y_pred)\n","    print(\"Confusion Matrix:\")\n","    print(cm)\n","\n","    # Store results\n","    results[threshold] = {\n","        \"best_params\": best_params,\n","        \"best_score\": best_score,\n","        \"test_accuracy\": accuracy,\n","        \"test_precision\": precision,\n","        \"test_recall\": recall,\n","        \"train_accuracy\": train_accuracy,\n","        \"train_precision\": train_precision,\n","        \"train_recall\": train_recall,\n","    }\n","\n","# Print results\n","for threshold, result in results.items():\n","    print(f\"Threshold: {threshold}\")\n","    print(\"Best parameters:\", result[\"best_params\"])\n","    print(\"Best score:\", result[\"best_score\"])\n","    print(\"Test accuracy:\", result[\"test_accuracy\"])\n","    print(\"Test precision:\", result[\"test_precision\"])\n","    print(\"Test recall:\", result[\"test_recall\"])\n","    print(\"Train accuracy:\", result[\"train_accuracy\"])\n","    print(\"Train precision:\", result[\"train_precision\"])\n","    print(\"Train recall:\", result[\"train_recall\"])"],"metadata":{"id":"ZhPEpgNhcJty","outputId":"72174b8b-3919-45b1-b7a5-fbf11b8b9cc0"},"execution_count":null,"outputs":[{"data":{"text/plain":"Features used: ['cp_asymptomatic', 'ca', 'exang', 'sex_Female', 'sex_Male', 'cp_atypical angina', 'slope_flat', 'fbs', 'slope_upsloping', 'oldpeak']\nConfusion Matrix:\n[[30  5]\n [ 5 20]]\nThreshold: 0.05\nBest parameters: {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\nBest score: 0.8074468085106383\nTest accuracy: 0.8333333333333334\nTest precision: 0.8\nTest recall: 0.8\nTrain accuracy: 0.8493723849372385\nTrain precision: 0.8611111111111112\nTrain recall: 0.8157894736842105\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]}],"metadata":{"orig_nbformat":4,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"hex_info":{"author":"Matt Rothman","project_id":"0f71f051-16c2-4835-862f-50b2f22b95e5","version":"draft","exported_date":"Sun Dec 15 2024 22:10:21 GMT+0000 (Coordinated Universal Time)"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}