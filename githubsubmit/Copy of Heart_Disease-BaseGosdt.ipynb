{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7F-pN5Gw_tZx"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import gosdt\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_check(df):\n",
    "    count_0 = len(df[df.iloc[:,-1]==0])\n",
    "    count_1 = len(df[df.iloc[:,-1]==1])\n",
    "    pct_pos = count_1/(count_0+count_1)\n",
    "\n",
    "    print(\"The number of positive samples is: \", count_1,\n",
    "          \"\\nThe number of negative samples is: \", count_0,\n",
    "          \"\\nThe percentage of positive samples is: \", pct_pos)\n",
    "    return pct_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age  trestbps  chol  fbs  thalch  exang  oldpeak  ca  Heart rate  \\\n",
      "0      1         1     0    1       1      0        1   0           0   \n",
      "1      1         1     1    0       0      1        1   1           1   \n",
      "2      1         0     0    0       0      1        1   1           0   \n",
      "3      0         0     1    0       1      0        1   0           0   \n",
      "4      0         0     0    0       1      0        1   0           0   \n",
      "..   ...       ...   ...  ...     ...    ...      ...  ..         ...   \n",
      "294    1         1     0    1       0      0        1   1           0   \n",
      "295    1         0     0    0       0      1        1   1           0   \n",
      "296    1         0     0    0       1      0        0   1           0   \n",
      "297    0         1     0    0       0      1        1   0           1   \n",
      "298    1         0     0    0       0      1        1   0           1   \n",
      "\n",
      "     Systolic blood pressure  ...  restecg_lv hypertrophy  restecg_normal  \\\n",
      "0                          1  ...                       1               0   \n",
      "1                          0  ...                       1               0   \n",
      "2                          1  ...                       1               0   \n",
      "3                          0  ...                       0               1   \n",
      "4                          0  ...                       1               0   \n",
      "..                       ...  ...                     ...             ...   \n",
      "294                        0  ...                       0               1   \n",
      "295                        0  ...                       0               1   \n",
      "296                        0  ...                       1               0   \n",
      "297                        0  ...                       0               1   \n",
      "298                        0  ...                       0               1   \n",
      "\n",
      "     restecg_st-t abnormality  slope_downsloping  slope_flat  slope_upsloping  \\\n",
      "0                           0                  1           0                0   \n",
      "1                           0                  0           1                0   \n",
      "2                           0                  0           1                0   \n",
      "3                           0                  1           0                0   \n",
      "4                           0                  0           0                1   \n",
      "..                        ...                ...         ...              ...   \n",
      "294                         0                  0           1                0   \n",
      "295                         0                  0           1                0   \n",
      "296                         0                  0           1                0   \n",
      "297                         0                  0           1                0   \n",
      "298                         0                  0           1                0   \n",
      "\n",
      "     thal_fixed defect  thal_normal  thal_reversable defect  num  \n",
      "0                    1            0                       0    0  \n",
      "1                    0            1                       0    1  \n",
      "2                    0            0                       1    1  \n",
      "3                    0            1                       0    0  \n",
      "4                    0            1                       0    0  \n",
      "..                 ...          ...                     ...  ...  \n",
      "294                  0            0                       1    1  \n",
      "295                  0            0                       1    1  \n",
      "296                  0            1                       0    1  \n",
      "297                  0            0                       1    1  \n",
      "298                  0            0                       1    1  \n",
      "\n",
      "[299 rows x 33 columns]\n",
      "The number of positive samples is:  139 \n",
      "The number of negative samples is:  160 \n",
      "The percentage of positive samples is:  0.46488294314381273\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"binarized_heart_disease.csv\")\n",
    "print(df)\n",
    "balance_check(df)\n",
    "y = df['num']\n",
    "X = df.drop(columns=['num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T1aLXtBD_tZ1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PzVbo0V8_tZ1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "sUwqLqPG_tZ1",
    "outputId": "1e09dc91-1942-4897-8d90-8ed668b861ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization: 0.2; Fold 1; Train set: 83, Validation set: 21\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\n",
      "bounds: [0.604819..0.604819] (0.000000) loss=0.204819, iterations=5\n",
      "Regularization: 0.2; Fold 1; Training Accuracy: 0.7952, Validation Accuracy: 0.6190, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Regularization: 0.2; Fold 2; Train set: 83, Validation set: 21\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\n",
      "bounds: [0.640964..0.640964] (0.000000) loss=0.240964, iterations=19\n",
      "Regularization: 0.2; Fold 2; Training Accuracy: 0.7590, Validation Accuracy: 0.8571, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Regularization: 0.2; Fold 3; Train set: 83, Validation set: 21\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\n",
      "bounds: [0.604819..0.604819] (0.000000) loss=0.204819, iterations=7\n",
      "Regularization: 0.2; Fold 3; Training Accuracy: 0.7952, Validation Accuracy: 0.7143, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Regularization: 0.2; Fold 4; Train set: 83, Validation set: 21\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\n",
      "bounds: [0.616867..0.616867] (0.000000) loss=0.216867, iterations=11\n",
      "Regularization: 0.2; Fold 4; Training Accuracy: 0.7831, Validation Accuracy: 0.7619, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Regularization: 0.2; Fold 5; Train set: 84, Validation set: 20\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\n",
      "bounds: [0.578571..0.578571] (0.000000) loss=0.178571, iterations=0\n",
      "Regularization: 0.2; Fold 5; Training Accuracy: 0.8214, Validation Accuracy: 0.6000, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Regularization: 0.1; Fold 1; Train set: 83, Validation set: 21\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.002 (user, system, wall), mem=0 MB\n",
      "bounds: [0.404819..0.404819] (0.000000) loss=0.204819, iterations=57\n",
      "Regularization: 0.1; Fold 1; Training Accuracy: 0.7952, Validation Accuracy: 0.6190, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Regularization: 0.1; Fold 2; Train set: 83, Validation set: 21\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.004 (user, system, wall), mem=0 MB\n",
      "bounds: [0.440964..0.440964] (0.000000) loss=0.240964, iterations=133\n",
      "Regularization: 0.1; Fold 2; Training Accuracy: 0.7590, Validation Accuracy: 0.8571, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Regularization: 0.1; Fold 3; Train set: 83, Validation set: 21\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.002 (user, system, wall), mem=0 MB\n",
      "bounds: [0.404819..0.404819] (0.000000) loss=0.204819, iterations=66\n",
      "Regularization: 0.1; Fold 3; Training Accuracy: 0.7952, Validation Accuracy: 0.7143, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Regularization: 0.1; Fold 4; Train set: 83, Validation set: 21\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.002 (user, system, wall), mem=0 MB\n",
      "bounds: [0.416867..0.416867] (0.000000) loss=0.216867, iterations=84\n",
      "Regularization: 0.1; Fold 4; Training Accuracy: 0.7831, Validation Accuracy: 0.7619, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Regularization: 0.1; Fold 5; Train set: 84, Validation set: 20\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\n",
      "bounds: [0.378571..0.378571] (0.000000) loss=0.178571, iterations=23\n",
      "Regularization: 0.1; Fold 5; Training Accuracy: 0.8214, Validation Accuracy: 0.6000, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Regularization: 0.05; Fold 1; Train set: 83, Validation set: 21\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.054 (user, system, wall), mem=0 MB\n",
      "bounds: [0.296386..0.296386] (0.000000) loss=0.096386, iterations=1640\n",
      "Regularization: 0.05; Fold 1; Training Accuracy: 0.9036, Validation Accuracy: 0.8095, Number of Leaves: 4, Number of Nodes: 7\n",
      "\n",
      "Regularization: 0.05; Fold 2; Train set: 83, Validation set: 21\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.177 (user, system, wall), mem=0 MB\n",
      "bounds: [0.306626..0.306626] (0.000000) loss=0.156626, iterations=5515\n",
      "Regularization: 0.05; Fold 2; Training Accuracy: 0.8434, Validation Accuracy: 0.8571, Number of Leaves: 3, Number of Nodes: 5\n",
      "\n",
      "Regularization: 0.05; Fold 3; Train set: 83, Validation set: 21\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.068 (user, system, wall), mem=0 MB\n",
      "bounds: [0.284337..0.284337] (0.000000) loss=0.084337, iterations=2072\n",
      "Regularization: 0.05; Fold 3; Training Accuracy: 0.9157, Validation Accuracy: 0.8571, Number of Leaves: 4, Number of Nodes: 7\n",
      "\n",
      "Regularization: 0.05; Fold 4; Train set: 83, Validation set: 21\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.102 (user, system, wall), mem=0 MB\n",
      "bounds: [0.284337..0.284337] (0.000000) loss=0.084337, iterations=3234\n",
      "Regularization: 0.05; Fold 4; Training Accuracy: 0.9157, Validation Accuracy: 0.8571, Number of Leaves: 4, Number of Nodes: 7\n",
      "\n",
      "Regularization: 0.05; Fold 5; Train set: 84, Validation set: 20\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.030 (user, system, wall), mem=0 MB\n",
      "bounds: [0.271429..0.271429] (0.000000) loss=0.071429, iterations=979\n",
      "Regularization: 0.05; Fold 5; Training Accuracy: 0.9286, Validation Accuracy: 0.8000, Number of Leaves: 4, Number of Nodes: 7\n",
      "\n",
      "Final Test Accuracy with best regularization 0.05: 0.7333\n",
      "Test Precision (macro): 0.7928\n",
      "Test Recall (macro): 0.7173\n",
      "Confusion Matrix:\n",
      "[[46  2]\n",
      " [22 20]]\n",
      "# of leaves: 3\n",
      "# of nodes: 5\n",
      "Confusion Matrix: \n",
      "<bound method GOSDT.confusion of <gosdt.model.gosdt.GOSDT object at 0x7fc961493b50>>\n",
      "Tree structure: \n",
      "if cp_asymptomatic = 1 and thal_normal = 1 then:\n",
      "    predicted class: 0\n",
      "    misclassification penalty: 0.048\n",
      "    complexity penalty: 0.05\n",
      "\n",
      "else if cp_asymptomatic = 1 and thal_normal != 1 then:\n",
      "    predicted class: 1\n",
      "    misclassification penalty: 0.012\n",
      "    complexity penalty: 0.05\n",
      "\n",
      "else if cp_asymptomatic != 1 then:\n",
      "    predicted class: 0\n",
      "    misclassification penalty: 0.096\n",
      "    complexity penalty: 0.05\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"from sklearn.metrics import precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import pandas as pd\n",
    "import gosdt\n",
    "\n",
    "\n",
    "# Function to visualize the tree\n",
    "def visualize_tree(model):\n",
    "    dot_data = model.export_graph()  # This function needs to be supported by your GOSDT implementation\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    return graph\n",
    "\n",
    "# Step 1: Split the dataset into training, validation, and test sets\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp)  # 0.50 * 0.30 = 0.15\n",
    "\n",
    "# Reduce the number of folds to 5\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "regularization = [0.2,0.1,.05]\n",
    "hp_grid = pd.DataFrame(columns=['regularization', 'average_validation_accuracy'])\n",
    "\n",
    "# Lambda function to compute mean\n",
    "\n",
    "\n",
    "for reg in regularization:\n",
    "    cnt = 1\n",
    "    val_accuracy = []\n",
    "    best_model = None\n",
    "    best_val_acc = 0\n",
    "\n",
    "    for train_index, val_index in kf.split(X_train, y_train):\n",
    "        print(f'Regularization: {reg}; Fold {cnt}; Train set: {len(train_index)}, Validation set: {len(val_index)}')\n",
    "\n",
    "        kfX_train = X_train.iloc[train_index, :]\n",
    "        kfX_val = X_train.iloc[val_index, :]\n",
    "        kfy_train = y_train.iloc[train_index]\n",
    "        kfy_val = y_train.iloc[val_index]\n",
    "\n",
    "        config = {\n",
    "            \"regularization\": reg,\n",
    "            \"depth_budget\": 6,  # Increase this value to allow more depth and more leaves\n",
    "            \"min_samples_leaf\": 2  # Decrease this value to allow more leaves\n",
    "        }\n",
    "        \n",
    "        model = gosdt.GOSDT(config)\n",
    "        model.fit(kfX_train, kfy_train)\n",
    "\n",
    "        train_acc = model.score(kfX_train, kfy_train)\n",
    "        val_acc = model.score(kfX_val, kfy_val)\n",
    "        n_leaves = model.leaves()\n",
    "        n_nodes = model.nodes()\n",
    "\n",
    "        # Store validation accuracy and check for the best model\n",
    "        val_accuracy.append(val_acc)\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model = model  # Keep a reference to the best model\n",
    "\n",
    "        print(f'Regularization: {reg}; Fold {cnt}; Training Accuracy: {train_acc:.4f}, Validation Accuracy: {val_acc:.4f}, Number of Leaves: {n_leaves}, Number of Nodes: {n_nodes}\\n')\n",
    "        cnt += 1\n",
    "    \n",
    "    # Calculate mean validation accuracy using the lambda function\n",
    "  \n",
    "\n",
    "# Final evaluation on the test set\n",
    "# Final evaluation on the test set\n",
    "if best_model is not None:\n",
    "    # Get predictions on the test set\n",
    "    test_preds = best_model.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy, precision, recall, and confusion matrix on the test set\n",
    "    test_acc = best_model.score(X_test, y_test)\n",
    "    test_precision = precision_score(y_test, test_preds, average='macro')  # Macro-average precision\n",
    "    test_recall = recall_score(y_test, test_preds, average='macro')  # Macro-average recall\n",
    "    cm = confusion_matrix(y_test, test_preds)  # Confusion matrix\n",
    "\n",
    "    # Print results\n",
    "    print(f'Final Test Accuracy with best regularization {reg}: {test_acc:.4f}')\n",
    "    print(f'Test Precision (macro): {test_precision:.4f}')\n",
    "    print(f'Test Recall (macro): {test_recall:.4f}')\n",
    "    print(f'Confusion Matrix:\\n{cm}')\n",
    "\n",
    "    print(f\"# of leaves: {best_model.leaves()}\")\n",
    "    print(f\"# of nodes: {best_model.nodes()}\")\n",
    "    print(f\"Confusion Matrix: \\n{best_model.confusion}\")\n",
    "    print(f\"Tree structure: \\n{best_model.tree}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization: 0.2; Fold 1; Train set: 83, Validation set: 21\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\n",
      "bounds: [0.604819..0.604819] (0.000000) loss=0.204819, iterations=5\n",
      "Regularization: 0.2; Fold 1; Training Accuracy: 0.7952, Training Precision: 0.7958, Training Recall: 0.7906, Validation Accuracy: 0.6190, Validation Precision: 0.6182, Validation Recall: 0.6182, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Regularization: 0.2; Fold 2; Train set: 83, Validation set: 21\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\n",
      "bounds: [0.640964..0.640964] (0.000000) loss=0.240964, iterations=19\n",
      "Regularization: 0.2; Fold 2; Training Accuracy: 0.7590, Training Precision: 0.7596, Training Recall: 0.7614, Validation Accuracy: 0.8571, Validation Precision: 0.8846, Validation Recall: 0.8636, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Regularization: 0.2; Fold 3; Train set: 83, Validation set: 21\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\n",
      "bounds: [0.604819..0.604819] (0.000000) loss=0.204819, iterations=7\n",
      "Regularization: 0.2; Fold 3; Training Accuracy: 0.7952, Training Precision: 0.7971, Training Recall: 0.7988, Validation Accuracy: 0.7143, Validation Precision: 0.7222, Validation Recall: 0.7182, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Regularization: 0.2; Fold 4; Train set: 83, Validation set: 21\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\n",
      "bounds: [0.616867..0.616867] (0.000000) loss=0.216867, iterations=11\n",
      "Regularization: 0.2; Fold 4; Training Accuracy: 0.7831, Training Precision: 0.7877, Training Recall: 0.7867, Validation Accuracy: 0.7619, Validation Precision: 0.7591, Validation Recall: 0.7639, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Regularization: 0.2; Fold 5; Train set: 84, Validation set: 20\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\n",
      "bounds: [0.578571..0.578571] (0.000000) loss=0.178571, iterations=0\n",
      "Regularization: 0.2; Fold 5; Training Accuracy: 0.8214, Training Precision: 0.8239, Training Recall: 0.8248, Validation Accuracy: 0.6000, Validation Precision: 0.6061, Validation Recall: 0.6061, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Regularization: 0.1; Fold 1; Train set: 83, Validation set: 21\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.002 (user, system, wall), mem=0 MB\n",
      "bounds: [0.404819..0.404819] (0.000000) loss=0.204819, iterations=57\n",
      "Regularization: 0.1; Fold 1; Training Accuracy: 0.7952, Training Precision: 0.7958, Training Recall: 0.7906, Validation Accuracy: 0.6190, Validation Precision: 0.6182, Validation Recall: 0.6182, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Regularization: 0.1; Fold 2; Train set: 83, Validation set: 21\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.004 (user, system, wall), mem=0 MB\n",
      "bounds: [0.440964..0.440964] (0.000000) loss=0.240964, iterations=133\n",
      "Regularization: 0.1; Fold 2; Training Accuracy: 0.7590, Training Precision: 0.7596, Training Recall: 0.7614, Validation Accuracy: 0.8571, Validation Precision: 0.8846, Validation Recall: 0.8636, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Regularization: 0.1; Fold 3; Train set: 83, Validation set: 21\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.002 (user, system, wall), mem=0 MB\n",
      "bounds: [0.404819..0.404819] (0.000000) loss=0.204819, iterations=66\n",
      "Regularization: 0.1; Fold 3; Training Accuracy: 0.7952, Training Precision: 0.7971, Training Recall: 0.7988, Validation Accuracy: 0.7143, Validation Precision: 0.7222, Validation Recall: 0.7182, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Regularization: 0.1; Fold 4; Train set: 83, Validation set: 21\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.002 (user, system, wall), mem=0 MB\n",
      "bounds: [0.416867..0.416867] (0.000000) loss=0.216867, iterations=84\n",
      "Regularization: 0.1; Fold 4; Training Accuracy: 0.7831, Training Precision: 0.7877, Training Recall: 0.7867, Validation Accuracy: 0.7619, Validation Precision: 0.7591, Validation Recall: 0.7639, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Regularization: 0.1; Fold 5; Train set: 84, Validation set: 20\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\n",
      "bounds: [0.378571..0.378571] (0.000000) loss=0.178571, iterations=23\n",
      "Regularization: 0.1; Fold 5; Training Accuracy: 0.8214, Training Precision: 0.8239, Training Recall: 0.8248, Validation Accuracy: 0.6000, Validation Precision: 0.6061, Validation Recall: 0.6061, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Regularization: 0.05; Fold 1; Train set: 83, Validation set: 21\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.055 (user, system, wall), mem=0 MB\n",
      "bounds: [0.296386..0.296386] (0.000000) loss=0.096386, iterations=1640\n",
      "Regularization: 0.05; Fold 1; Training Accuracy: 0.9036, Training Precision: 0.9026, Training Recall: 0.9050, Validation Accuracy: 0.8095, Validation Precision: 0.8194, Validation Recall: 0.8136, Number of Leaves: 4, Number of Nodes: 7\n",
      "\n",
      "Regularization: 0.05; Fold 2; Train set: 83, Validation set: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_58640/2710901064.py:88: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  hp_grid = hp_grid.append({'regularization': reg, 'average_validation_accuracy': avg_val_accuracy}, ignore_index=True)\n",
      "/tmp/ipykernel_58640/2710901064.py:88: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  hp_grid = hp_grid.append({'regularization': reg, 'average_validation_accuracy': avg_val_accuracy}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.193 (user, system, wall), mem=0 MB\n",
      "bounds: [0.306626..0.306626] (0.000000) loss=0.156626, iterations=5515\n",
      "Regularization: 0.05; Fold 2; Training Accuracy: 0.8434, Training Precision: 0.8743, Training Recall: 0.8310, Validation Accuracy: 0.8571, Validation Precision: 0.8611, Validation Recall: 0.8545, Number of Leaves: 3, Number of Nodes: 5\n",
      "\n",
      "Regularization: 0.05; Fold 3; Train set: 83, Validation set: 21\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.069 (user, system, wall), mem=0 MB\n",
      "bounds: [0.284337..0.284337] (0.000000) loss=0.084337, iterations=2072\n",
      "Regularization: 0.05; Fold 3; Training Accuracy: 0.9157, Training Precision: 0.9248, Training Recall: 0.9099, Validation Accuracy: 0.8571, Validation Precision: 0.8611, Validation Recall: 0.8545, Number of Leaves: 4, Number of Nodes: 7\n",
      "\n",
      "Regularization: 0.05; Fold 4; Train set: 83, Validation set: 21\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.117 (user, system, wall), mem=0 MB\n",
      "bounds: [0.284337..0.284337] (0.000000) loss=0.084337, iterations=3234\n",
      "Regularization: 0.05; Fold 4; Training Accuracy: 0.9157, Training Precision: 0.9241, Training Recall: 0.9117, Validation Accuracy: 0.8571, Validation Precision: 0.8606, Validation Recall: 0.8472, Number of Leaves: 4, Number of Nodes: 7\n",
      "\n",
      "Regularization: 0.05; Fold 5; Train set: 84, Validation set: 20\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.030 (user, system, wall), mem=0 MB\n",
      "bounds: [0.271429..0.271429] (0.000000) loss=0.071429, iterations=979\n",
      "Regularization: 0.05; Fold 5; Training Accuracy: 0.9286, Training Precision: 0.9347, Training Recall: 0.9248, Validation Accuracy: 0.8000, Validation Precision: 0.8132, Validation Recall: 0.7879, Number of Leaves: 4, Number of Nodes: 7\n",
      "\n",
      "\n",
      "--- Final Results ---\n",
      "Final Test Accuracy with best regularization 0.05: 0.7333\n",
      "Test Precision (macro): 0.7928\n",
      "Test Recall (macro): 0.7173\n",
      "Confusion Matrix:\n",
      "[[46  2]\n",
      " [22 20]]\n",
      "\n",
      "--- Summary of Train and Validation Metrics ---\n",
      "Training Accuracy: 0.8571\n",
      "Training Precision (macro): 0.8608\n",
      "Training Recall (macro): 0.8581\n",
      "Validation Accuracy: 0.6667\n",
      "Validation Precision (macro): 0.6751\n",
      "Validation Recall (macro): 0.6667\n",
      "# of leaves: 3\n",
      "# of nodes: 5\n",
      "Confusion Matrix: \n",
      "<bound method GOSDT.confusion of <gosdt.model.gosdt.GOSDT object at 0x7fc9614a53d0>>\n",
      "Tree structure: \n",
      "if cp_asymptomatic = 1 and thal_normal = 1 then:\n",
      "    predicted class: 0\n",
      "    misclassification penalty: 0.048\n",
      "    complexity penalty: 0.05\n",
      "\n",
      "else if cp_asymptomatic = 1 and thal_normal != 1 then:\n",
      "    predicted class: 1\n",
      "    misclassification penalty: 0.012\n",
      "    complexity penalty: 0.05\n",
      "\n",
      "else if cp_asymptomatic != 1 then:\n",
      "    predicted class: 0\n",
      "    misclassification penalty: 0.096\n",
      "    complexity penalty: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_58640/2710901064.py:88: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  hp_grid = hp_grid.append({'regularization': reg, 'average_validation_accuracy': avg_val_accuracy}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import pandas as pd\n",
    "import gosdt\n",
    "import graphviz\n",
    "\n",
    "# Function to visualize the tree\n",
    "def visualize_tree(model):\n",
    "    dot_data = model.export_graph()  # This function needs to be supported by your GOSDT implementation\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    return graph\n",
    "\n",
    "# Step 1: Split the dataset into training, validation, and test sets\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp)  # 0.50 * 0.30 = 0.15\n",
    "\n",
    "# Reduce the number of folds to 5\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "regularization = [0.2, 0.1, 0.05]\n",
    "hp_grid = pd.DataFrame(columns=['regularization', 'average_validation_accuracy'])\n",
    "\n",
    "# Variables to store overall metrics\n",
    "all_train_acc = []\n",
    "all_train_precision = []\n",
    "all_train_recall = []\n",
    "all_val_acc = []\n",
    "all_val_precision = []\n",
    "all_val_recall = []\n",
    "\n",
    "# Lambda function to compute mean\n",
    "for reg in regularization:\n",
    "    cnt = 1\n",
    "    val_accuracy = []\n",
    "    best_model = None\n",
    "    best_val_acc = 0\n",
    "\n",
    "    for train_index, val_index in kf.split(X_train, y_train):\n",
    "        print(f'Regularization: {reg}; Fold {cnt}; Train set: {len(train_index)}, Validation set: {len(val_index)}')\n",
    "\n",
    "        kfX_train = X_train.iloc[train_index, :]\n",
    "        kfX_val = X_train.iloc[val_index, :]\n",
    "        kfy_train = y_train.iloc[train_index]\n",
    "        kfy_val = y_train.iloc[val_index]\n",
    "\n",
    "        config = {\n",
    "            \"regularization\": reg,\n",
    "            \"depth_budget\": 6,  # Increase this value to allow more depth and more leaves\n",
    "            \"min_samples_leaf\": 2  # Decrease this value to allow more leaves\n",
    "        }\n",
    "        \n",
    "        model = gosdt.GOSDT(config)\n",
    "        model.fit(kfX_train, kfy_train)\n",
    "\n",
    "        train_preds = model.predict(kfX_train)\n",
    "        val_preds = model.predict(kfX_val)\n",
    "\n",
    "        # Calculate training metrics\n",
    "        train_acc = model.score(kfX_train, kfy_train)\n",
    "        train_precision = precision_score(kfy_train, train_preds, average='macro')\n",
    "        train_recall = recall_score(kfy_train, train_preds, average='macro')\n",
    "        \n",
    "        # Calculate validation metrics\n",
    "        val_acc = model.score(kfX_val, kfy_val)\n",
    "        val_precision = precision_score(kfy_val, val_preds, average='macro')\n",
    "        val_recall = recall_score(kfy_val, val_preds, average='macro')\n",
    "\n",
    "        n_leaves = model.leaves()\n",
    "        n_nodes = model.nodes()\n",
    "\n",
    "        # Store validation accuracy and check for the best model\n",
    "        val_accuracy.append(val_acc)\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model = model  # Keep a reference to the best model\n",
    "\n",
    "        # Print fold results\n",
    "        print(f'Regularization: {reg}; Fold {cnt}; '\n",
    "              f'Training Accuracy: {train_acc:.4f}, Training Precision: {train_precision:.4f}, '\n",
    "              f'Training Recall: {train_recall:.4f}, '\n",
    "              f'Validation Accuracy: {val_acc:.4f}, Validation Precision: {val_precision:.4f}, '\n",
    "              f'Validation Recall: {val_recall:.4f}, '\n",
    "              f'Number of Leaves: {n_leaves}, Number of Nodes: {n_nodes}\\n')\n",
    "        cnt += 1\n",
    "    \n",
    "    # Calculate mean validation accuracy\n",
    "    avg_val_accuracy = sum(val_accuracy) / len(val_accuracy)\n",
    "    hp_grid = hp_grid.append({'regularization': reg, 'average_validation_accuracy': avg_val_accuracy}, ignore_index=True)\n",
    "\n",
    "    # Store metrics for final output\n",
    "    all_train_acc.append(train_acc)\n",
    "    all_train_precision.append(train_precision)\n",
    "    all_train_recall.append(train_recall)\n",
    "    all_val_acc.append(val_acc)\n",
    "    all_val_precision.append(val_precision)\n",
    "    all_val_recall.append(val_recall)\n",
    "\n",
    "# Final evaluation on the test set\n",
    "if best_model is not None:\n",
    "    # Get predictions on the test set\n",
    "    test_preds = best_model.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy, precision, recall on the test set\n",
    "    test_acc = best_model.score(X_test, y_test)\n",
    "    test_precision = precision_score(y_test, test_preds, average='macro')\n",
    "    test_recall = recall_score(y_test, test_preds, average='macro')\n",
    "    cm = confusion_matrix(y_test, test_preds)\n",
    "\n",
    "    # Print final results\n",
    "    print(\"\\n--- Final Results ---\")\n",
    "    print(f'Final Test Accuracy with best regularization {reg}: {test_acc:.4f}')\n",
    "    print(f'Test Precision (macro): {test_precision:.4f}')\n",
    "    print(f'Test Recall (macro): {test_recall:.4f}')\n",
    "    print(f'Confusion Matrix:\\n{cm}')\n",
    "\n",
    "    # Print training and validation metrics\n",
    "    print(\"\\n--- Summary of Train and Validation Metrics ---\")\n",
    "    print(f\"Training Accuracy: {sum(all_train_acc) / len(all_train_acc):.4f}\")\n",
    "    print(f\"Training Precision (macro): {sum(all_train_precision) / len(all_train_precision):.4f}\")\n",
    "    print(f\"Training Recall (macro): {sum(all_train_recall) / len(all_train_recall):.4f}\")\n",
    "    \n",
    "    print(f\"Validation Accuracy: {sum(all_val_acc) / len(all_val_acc):.4f}\")\n",
    "    print(f\"Validation Precision (macro): {sum(all_val_precision) / len(all_val_precision):.4f}\")\n",
    "    print(f\"Validation Recall (macro): {sum(all_val_recall) / len(all_val_recall):.4f}\")\n",
    "\n",
    "    # Optionally, print out the best model's details\n",
    "    print(f\"# of leaves: {best_model.leaves()}\")\n",
    "    print(f\"# of nodes: {best_model.nodes()}\")\n",
    "    print(f\"Confusion Matrix: \\n{best_model.confusion}\")\n",
    "    print(f\"Tree structure: \\n{best_model.tree}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization: 0.2; Fold 1; Train set: 28, Validation set: 8\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\n",
      "bounds: [0.578571..0.578571] (0.000000) loss=0.178571, iterations=0\n",
      "Regularization: 0.2; Fold 1; Training Accuracy: 0.8214, Validation Accuracy: 0.5000, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Regularization: 0.2; Fold 2; Train set: 29, Validation set: 7\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\n",
      "bounds: [0.606897..0.606897] (0.000000) loss=0.206897, iterations=11\n",
      "Regularization: 0.2; Fold 2; Training Accuracy: 0.7931, Validation Accuracy: 0.8571, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Regularization: 0.2; Fold 3; Train set: 29, Validation set: 7\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\n",
      "bounds: [0.606897..0.606897] (0.000000) loss=0.206897, iterations=9\n",
      "Regularization: 0.2; Fold 3; Training Accuracy: 0.7931, Validation Accuracy: 0.8571, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Regularization: 0.2; Fold 4; Train set: 29, Validation set: 7\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\n",
      "bounds: [0.572414..0.572414] (0.000000) loss=0.172414, iterations=0\n",
      "Regularization: 0.2; Fold 4; Training Accuracy: 0.8276, Validation Accuracy: 0.5714, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Regularization: 0.2; Fold 5; Train set: 29, Validation set: 7\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\n",
      "bounds: [0.572414..0.572414] (0.000000) loss=0.172414, iterations=0\n",
      "Regularization: 0.2; Fold 5; Training Accuracy: 0.8276, Validation Accuracy: 0.7143, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Regularization: 0.1; Fold 1; Train set: 28, Validation set: 8\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\n",
      "bounds: [0.378571..0.378571] (0.000000) loss=0.178571, iterations=33\n",
      "Regularization: 0.1; Fold 1; Training Accuracy: 0.8214, Validation Accuracy: 0.5000, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Regularization: 0.1; Fold 2; Train set: 29, Validation set: 7\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.002 (user, system, wall), mem=0 MB\n",
      "bounds: [0.406897..0.406897] (0.000000) loss=0.206897, iterations=62\n",
      "Regularization: 0.1; Fold 2; Training Accuracy: 0.7931, Validation Accuracy: 0.8571, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Regularization: 0.1; Fold 3; Train set: 29, Validation set: 7\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.001 (user, system, wall), mem=0 MB\n",
      "bounds: [0.406897..0.406897] (0.000000) loss=0.206897, iterations=62\n",
      "Regularization: 0.1; Fold 3; Training Accuracy: 0.7931, Validation Accuracy: 0.8571, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Regularization: 0.1; Fold 4; Train set: 29, Validation set: 7\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\n",
      "bounds: [0.372414..0.372414] (0.000000) loss=0.172414, iterations=35\n",
      "Regularization: 0.1; Fold 4; Training Accuracy: 0.8276, Validation Accuracy: 0.5714, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Regularization: 0.1; Fold 5; Train set: 29, Validation set: 7\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\n",
      "bounds: [0.372414..0.372414] (0.000000) loss=0.172414, iterations=27\n",
      "Regularization: 0.1; Fold 5; Training Accuracy: 0.8276, Validation Accuracy: 0.7143, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Final Test Accuracy with best regularization 0.1: 0.7500\n",
      "Test Precision (macro): 0.7652\n",
      "Test Recall (macro): 0.7569\n",
      "Confusion Matrix:\n",
      "[[13  2]\n",
      " [ 6 11]]\n",
      "# of leaves: 2\n",
      "# of nodes: 3\n",
      "Confusion Matrix: \n",
      "<bound method GOSDT.confusion of <gosdt.model.gosdt.GOSDT object at 0x7f0d156cdf10>>\n",
      "Tree structure: \n",
      "if ca = 1 then:\n",
      "    predicted class: 1\n",
      "    misclassification penalty: 0.138\n",
      "    complexity penalty: 0.1\n",
      "\n",
      "else if ca != 1 then:\n",
      "    predicted class: 0\n",
      "    misclassification penalty: 0.069\n",
      "    complexity penalty: 0.1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import gosdt\n",
    "\n",
    "\n",
    "# Step 1: Split the dataset into training, validation, and test sets\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X_train, y_train, test_size=0.30, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42)  # 0.50 * 0.30 = 0.15\n",
    "\n",
    "# Reduce the number of folds to 5\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "regularization = [0.2, 0.1]\n",
    "hp_grid = pd.DataFrame(columns=['regularization', 'average_validation_accuracy'])\n",
    "\n",
    "# Lambda function to compute mean\n",
    "for reg in regularization:\n",
    "    cnt = 1\n",
    "    val_accuracy = []\n",
    "    best_model = None\n",
    "    best_val_acc = 0\n",
    "\n",
    "    for train_index, val_index in kf.split(X_train, y_train):\n",
    "        print(f'Regularization: {reg}; Fold {cnt}; Train set: {len(train_index)}, Validation set: {len(val_index)}')\n",
    "\n",
    "        kfX_train = X_train.iloc[train_index, :]\n",
    "        kfX_val = X_train.iloc[val_index, :]\n",
    "        kfy_train = y_train.iloc[train_index]\n",
    "        kfy_val = y_train.iloc[val_index]\n",
    "\n",
    "        config = {\n",
    "            \"regularization\": reg,\n",
    "            \"depth_budget\": 7,  # Increase this value to allow more depth and more leaves\n",
    "            \"min_samples_leaf\": 2  # Decrease this value to allow more leaves\n",
    "        }\n",
    "        \n",
    "        model = gosdt.GOSDT(config)\n",
    "        model.fit(kfX_train, kfy_train)\n",
    "\n",
    "        train_acc = model.score(kfX_train, kfy_train)\n",
    "        val_acc = model.score(kfX_val, kfy_val)\n",
    "        n_leaves = model.leaves()\n",
    "        n_nodes = model.nodes()\n",
    "\n",
    "        # Store validation accuracy and check for the best model\n",
    "        val_accuracy.append(val_acc)\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model = model  # Keep a reference to the best model\n",
    "\n",
    "        print(f'Regularization: {reg}; Fold {cnt}; Training Accuracy: {train_acc:.4f}, Validation Accuracy: {val_acc:.4f}, Number of Leaves: {n_leaves}, Number of Nodes: {n_nodes}\\n')\n",
    "        cnt += 1\n",
    "\n",
    "# Final evaluation on the test set\n",
    "if best_model is not None:\n",
    "    # Get predictions on the test set\n",
    "    test_preds = best_model.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy, precision, recall, and confusion matrix on the test set\n",
    "    test_acc = best_model.score(X_test, y_test)\n",
    "    test_precision = precision_score(y_test, test_preds, average='macro')  # Macro-average precision\n",
    "    test_recall = recall_score(y_test, test_preds, average='macro')  # Macro-average recall\n",
    "    cm = confusion_matrix(y_test, test_preds)  # Confusion matrix\n",
    "\n",
    "    # Print results\n",
    "    print(f'Final Test Accuracy with best regularization {reg}: {test_acc:.4f}')\n",
    "    print(f'Test Precision (macro): {test_precision:.4f}')\n",
    "    print(f'Test Recall (macro): {test_recall:.4f}')\n",
    "    print(f'Confusion Matrix:\\n{cm}')\n",
    "\n",
    "    print(f\"# of leaves: {best_model.leaves()}\")\n",
    "    print(f\"# of nodes: {best_model.nodes()}\")\n",
    "    print(f\"Confusion Matrix: \\n{best_model.confusion}\")\n",
    "    print(f\"Tree structure: \\n{best_model.tree}\")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization: 0.2; Fold 1; Train set: 58, Validation set: 15\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\n",
      "bounds: [0.606897..0.606897] (0.000000) loss=0.206897, iterations=9\n",
      "Regularization: 0.2; Fold 1; Training Accuracy: 0.7931, Validation Accuracy: 0.7333, Precision: 0.7467, Recall: 0.7333, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Regularization: 0.2; Fold 2; Train set: 58, Validation set: 15\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\n",
      "bounds: [0.606897..0.606897] (0.000000) loss=0.206897, iterations=9\n",
      "Regularization: 0.2; Fold 2; Training Accuracy: 0.7931, Validation Accuracy: 0.7333, Precision: 0.7333, Recall: 0.7333, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Regularization: 0.2; Fold 3; Train set: 58, Validation set: 15\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.001 (user, system, wall), mem=0 MB\n",
      "bounds: [0.624138..0.624138] (0.000000) loss=0.224138, iterations=29\n",
      "Regularization: 0.2; Fold 3; Training Accuracy: 0.7759, Validation Accuracy: 0.6000, Precision: 0.6148, Recall: 0.6000, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Regularization: 0.2; Fold 4; Train set: 59, Validation set: 14\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.001 (user, system, wall), mem=0 MB\n",
      "bounds: [0.654237..0.654237] (0.000000) loss=0.254237, iterations=43\n",
      "Regularization: 0.2; Fold 4; Training Accuracy: 0.7458, Validation Accuracy: 0.5714, Precision: 0.5714, Recall: 0.5714, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Regularization: 0.2; Fold 5; Train set: 59, Validation set: 14\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.000 (user, system, wall), mem=0 MB\n",
      "bounds: [0.586441..0.586441] (0.000000) loss=0.186441, iterations=0\n",
      "Regularization: 0.2; Fold 5; Training Accuracy: 0.8136, Validation Accuracy: 0.6429, Precision: 0.6750, Recall: 0.6429, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Regularization: 0.1; Fold 1; Train set: 58, Validation set: 15\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.008 (user, system, wall), mem=0 MB\n",
      "bounds: [0.406897..0.406897] (0.000000) loss=0.206897, iterations=174\n",
      "Regularization: 0.1; Fold 1; Training Accuracy: 0.7931, Validation Accuracy: 0.7333, Precision: 0.7467, Recall: 0.7333, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Regularization: 0.1; Fold 2; Train set: 58, Validation set: 15\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.008 (user, system, wall), mem=0 MB\n",
      "bounds: [0.406897..0.406897] (0.000000) loss=0.206897, iterations=179\n",
      "Regularization: 0.1; Fold 2; Training Accuracy: 0.7931, Validation Accuracy: 0.7333, Precision: 0.7333, Recall: 0.7333, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Regularization: 0.1; Fold 3; Train set: 58, Validation set: 15\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.012 (user, system, wall), mem=0 MB\n",
      "bounds: [0.424138..0.424138] (0.000000) loss=0.224138, iterations=309\n",
      "Regularization: 0.1; Fold 3; Training Accuracy: 0.7759, Validation Accuracy: 0.6000, Precision: 0.6148, Recall: 0.6000, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Regularization: 0.1; Fold 4; Train set: 59, Validation set: 14\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.025 (user, system, wall), mem=0 MB\n",
      "bounds: [0.454237..0.454237] (0.000000) loss=0.254237, iterations=667\n",
      "Regularization: 0.1; Fold 4; Training Accuracy: 0.7458, Validation Accuracy: 0.5714, Precision: 0.5714, Recall: 0.5714, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Regularization: 0.1; Fold 5; Train set: 59, Validation set: 14\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.002 (user, system, wall), mem=0 MB\n",
      "bounds: [0.386441..0.386441] (0.000000) loss=0.186441, iterations=79\n",
      "Regularization: 0.1; Fold 5; Training Accuracy: 0.8136, Validation Accuracy: 0.6429, Precision: 0.6750, Recall: 0.6429, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "Final Test Accuracy with best regularization 0.1: 0.7302\n",
      "Test Precision: 0.7539, Test Recall: 0.7302\n",
      "Training accuracy: 0.8135593220338984\n",
      "Validation accuracy: 0.6428571428571429\n",
      "Test accuracy: 0.7301587301587301\n",
      "Test precision: 0.7539042498719919\n",
      "Test recall: 0.7301587301587301\n",
      "# of leaves: 2\n",
      "# of nodes: 3\n",
      "<bound method GOSDT.confusion of <gosdt.model.gosdt.GOSDT object at 0x7f9dfec05210>>\n",
      "if cp_asymptomatic = 1 then:\n",
      "    predicted class: 1\n",
      "    misclassification penalty: 0.119\n",
      "    complexity penalty: 0.1\n",
      "\n",
      "else if cp_asymptomatic != 1 then:\n",
      "    predicted class: 0\n",
      "    misclassification penalty: 0.068\n",
      "    complexity penalty: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_64210/55344751.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  hp_grid = hp_grid.append({\n",
      "/tmp/ipykernel_64210/55344751.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  hp_grid = hp_grid.append({\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import pandas as pd\n",
    "import gosdt\n",
    "import graphviz\n",
    "\n",
    "# Function to visualize the tree\n",
    "def visualize_tree(model):\n",
    "    dot_data = model.export_graph()  # This function needs to be supported by your GOSDT implementation\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    return graph\n",
    "\n",
    "# Step 1: Split the dataset into training, validation, and test sets\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X_train, y_train, test_size=0.30, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42)  # 0.50 * 0.30 = 0.15\n",
    "# Reduce the number of folds to 5\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "regularization = [0.2, 0.1]\n",
    "hp_grid = pd.DataFrame(columns=['regularization', 'average_validation_accuracy', 'average_precision', 'average_recall'])\n",
    "\n",
    "# Lambda function to compute mean\n",
    "for reg in regularization:\n",
    "    cnt = 1\n",
    "    val_accuracy = []\n",
    "    val_precision = []\n",
    "    val_recall = []\n",
    "    best_model = None\n",
    "    best_val_acc = 0\n",
    "\n",
    "    for train_index, val_index in kf.split(X_train, y_train):\n",
    "        print(f'Regularization: {reg}; Fold {cnt}; Train set: {len(train_index)}, Validation set: {len(val_index)}')\n",
    "\n",
    "        kfX_train = X_train.iloc[train_index, :]\n",
    "        kfX_val = X_train.iloc[val_index, :]\n",
    "        kfy_train = y_train.iloc[train_index]\n",
    "        kfy_val = y_train.iloc[val_index]\n",
    "\n",
    "        config = {\n",
    "            \"regularization\": reg,\n",
    "            \"depth_budget\": 5,\n",
    "            \"min_samples_leaf\": 5\n",
    "        }\n",
    "        \n",
    "        model = gosdt.GOSDT(config)\n",
    "        model.fit(kfX_train, kfy_train)\n",
    "\n",
    "        train_acc = model.score(kfX_train, kfy_train)\n",
    "        val_acc = model.score(kfX_val, kfy_val)\n",
    "        val_pred = model.predict(kfX_val)  # Assuming your model has a predict method\n",
    "        precision = precision_score(kfy_val, val_pred, average='weighted')\n",
    "        recall = recall_score(kfy_val, val_pred, average='weighted')\n",
    "        \n",
    "        n_leaves = model.leaves()\n",
    "        n_nodes = model.nodes()\n",
    "\n",
    "        # Store validation accuracy, precision, and recall, and check for the best model\n",
    "        val_accuracy.append(val_acc)\n",
    "        val_precision.append(precision)\n",
    "        val_recall.append(recall)\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model = model  # Keep a reference to the best model\n",
    "\n",
    "        print(f'Regularization: {reg}; Fold {cnt}; Training Accuracy: {train_acc:.4f}, Validation Accuracy: {val_acc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, Number of Leaves: {n_leaves}, Number of Nodes: {n_nodes}\\n')\n",
    "        cnt += 1\n",
    "    \n",
    "    # Calculate mean validation metrics\n",
    "    hp_grid = hp_grid.append({\n",
    "        'regularization': reg,\n",
    "        'average_validation_accuracy': sum(val_accuracy) / len(val_accuracy),\n",
    "        'average_precision': sum(val_precision) / len(val_precision),\n",
    "        'average_recall': sum(val_recall) / len(val_recall)\n",
    "    }, ignore_index=True)\n",
    "\n",
    "# Final evaluation on the test set\n",
    "if best_model is not None:\n",
    "    test_pred = best_model.predict(X_test)\n",
    "    test_acc = best_model.score(X_test, y_test)\n",
    "    test_precision = precision_score(y_test, test_pred, average='weighted')\n",
    "    test_recall = recall_score(y_test, test_pred, average='weighted')\n",
    "\n",
    "    print(f'Final Test Accuracy with best regularization {reg}: {test_acc:.4f}')\n",
    "    print(f'Test Precision: {test_precision:.4f}, Test Recall: {test_recall:.4f}')\n",
    "\n",
    "print(\"Training accuracy: {}\".format(train_acc))\n",
    "print(\"Validation accuracy: {}\".format(val_acc))\n",
    "print(\"Test accuracy: {}\".format(test_acc))\n",
    "print(\"Test precision: {}\".format(test_precision))\n",
    "print(\"Test recall: {}\".format(test_recall))\n",
    "print(\"# of leaves: {}\".format(n_leaves))\n",
    "print(\"# of nodes: {}\".format(n_nodes))\n",
    "print(model.confusion)\n",
    "print(model.tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "FVmEzoAj_tZ1",
    "outputId": "c0d1d658-9630-4155-d2d3-5e75d56e5fb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   regularization  average_validation_accuracy  average_precision  \\\n",
      "0             0.2                     0.741696            0.74341   \n",
      "1             0.1                     0.741696            0.74341   \n",
      "\n",
      "   average_recall  \n",
      "0        0.741696  \n",
      "1        0.741696  \n"
     ]
    }
   ],
   "source": [
    "hp_grid.max()\n",
    "print(hp_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "PiXnDPv2_tZ2",
    "outputId": "82b63d9c-dc96-44b0-c48d-aa89ee8568c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/7.682 (user, system, wall), mem=0 MB\n",
      "bounds: [0.349665..0.349665] (0.000000) loss=0.229665, iterations=80540\n",
      "Training Accuracy: 0.7703349282296651, Test Accuracy: 0.7333333333333333, Number of Leaves: 2, Number of Nodes: 3\n",
      "\n",
      "if thal_normal = 1 then:\n",
      "    predicted class: 0\n",
      "    misclassification penalty: 0.12\n",
      "    complexity penalty: 0.06\n",
      "\n",
      "else if thal_normal != 1 then:\n",
      "    predicted class: 1\n",
      "    misclassification penalty: 0.11\n",
      "    complexity penalty: 0.06\n"
     ]
    }
   ],
   "source": [
    "import gosdt\n",
    "\n",
    "config = {\n",
    "            \"regularization\": 0.06,\n",
    "            \"depth_budget\": 0\n",
    "        }\n",
    "model = gosdt.GOSDT(config)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "train_acc = model.score(X_train, y_train)\n",
    "test_acc = model.score(X_test, y_test)\n",
    "n_leaves = model.leaves()\n",
    "n_nodes = model.nodes()\n",
    "\n",
    "print(f'Training Accuracy: {train_acc}, Test Accuracy: {test_acc}, Number of Leaves: {n_leaves}, Number of Nodes: {n_nodes}\\n')\n",
    "print(model.tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cpPUkrbZ_tZ2",
    "outputId": "de47280a-7764-4c61-8006-bf2d744d4aef",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computedRashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computedRashomon set has already been computed\n",
      "\n",
      "Rashomon set has already been computedRashomon set has already been computed\n",
      "\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computedRashomon set has already been computed\n",
      "\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computedRashomon set has already been computed\n",
      "\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computedRashomon set has already been computed\n",
      "\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computedRashomon set has already been computed\n",
      "\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computedRashomon set has already been computed\n",
      "\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computedRashomon set has already been computed\n",
      "\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computedRashomon set has already been computed\n",
      "\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computedRashomon set has already been computed\n",
      "\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Rashomon set has already been computed\n",
      "Completed final processing in 7.033348083496094e-05 seconds\n",
      "Processing ours with counts\n",
      "Starting var 0\n",
      "Starting var 1\n",
      "Starting var 2\n",
      "Starting var 3\n",
      "Starting var 4\n",
      "Starting var 5\n",
      "Starting var 6\n",
      "Starting var 7\n",
      "Starting var 8\n",
      "Starting var 9\n",
      "Starting var 10\n",
      "Starting var 11\n",
      "Starting var 12\n",
      "Variable 0 ------------\n",
      "Box and whiskers mean: 1.2335811384723961e-17\n",
      "Box and whiskers median: 0.0\n",
      "Box and whiskers range: (-4.440892098500626e-16, 4.440892098500626e-16)\n",
      "Variable 1 ------------\n",
      "Box and whiskers mean: 1.2335811384723961e-17\n",
      "Box and whiskers median: 0.0\n",
      "Box and whiskers range: (-4.440892098500626e-16, 4.440892098500626e-16)\n",
      "Variable 2 ------------\n",
      "Box and whiskers mean: 0.06995260683410577\n",
      "Box and whiskers median: 0.058745874587458724\n",
      "Box and whiskers range: (-0.09966996699669972, 0.2303630363036303)\n",
      "Variable 3 ------------\n",
      "Box and whiskers mean: 1.2335811384723961e-17\n",
      "Box and whiskers median: 0.0\n",
      "Box and whiskers range: (-4.440892098500626e-16, 4.440892098500626e-16)\n",
      "Variable 4 ------------\n",
      "Box and whiskers mean: 1.2335811384723961e-17\n",
      "Box and whiskers median: 0.0\n",
      "Box and whiskers range: (-4.440892098500626e-16, 4.440892098500626e-16)\n",
      "Variable 5 ------------\n",
      "Box and whiskers mean: 1.2335811384723961e-17\n",
      "Box and whiskers median: 0.0\n",
      "Box and whiskers range: (-4.440892098500626e-16, 4.440892098500626e-16)\n",
      "Variable 6 ------------\n",
      "Box and whiskers mean: 1.2335811384723961e-17\n",
      "Box and whiskers median: 0.0\n",
      "Box and whiskers range: (-4.440892098500626e-16, 4.440892098500626e-16)\n",
      "Variable 7 ------------\n",
      "Box and whiskers mean: 1.2335811384723961e-17\n",
      "Box and whiskers median: 0.0\n",
      "Box and whiskers range: (-4.440892098500626e-16, 4.440892098500626e-16)\n",
      "Variable 8 ------------\n",
      "Box and whiskers mean: 0.041012429253727375\n",
      "Box and whiskers median: 0.031023102310230977\n",
      "Box and whiskers range: (-0.088943894389439, 0.1552805280528053)\n",
      "Variable 9 ------------\n",
      "Box and whiskers mean: 1.2335811384723961e-17\n",
      "Box and whiskers median: 0.0\n",
      "Box and whiskers range: (-4.440892098500626e-16, 4.440892098500626e-16)\n",
      "Variable 10 ------------\n",
      "Box and whiskers mean: 0.03907384233912689\n",
      "Box and whiskers median: 0.03168316831683182\n",
      "Box and whiskers range: (-0.07260726072607243, 0.14125412541254118)\n",
      "Variable 11 ------------\n",
      "Box and whiskers mean: 0.07270119714107239\n",
      "Box and whiskers median: 0.06864686468646863\n",
      "Box and whiskers range: (-0.09191419141914203, 0.22887788778877904)\n",
      "Variable 12 ------------\n",
      "Box and whiskers mean: 0.062002654565316354\n",
      "Box and whiskers median: 0.05016501650165017\n",
      "Box and whiskers range: (-0.09191419141914142, 0.20511551155115454)\n",
      "Variable 13 ------------\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "13",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m15\u001b[39m):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVariable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBox and whiskers mean:\u001b[39m\u001b[38;5;124m'\u001b[39m, RID\u001b[38;5;241m.\u001b[39mmean(v))\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBox and whiskers median:\u001b[39m\u001b[38;5;124m'\u001b[39m, RID\u001b[38;5;241m.\u001b[39mmedian(v))\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBox and whiskers range:\u001b[39m\u001b[38;5;124m'\u001b[39m, RID\u001b[38;5;241m.\u001b[39mbwr(v))\n",
      "File \u001b[0;32m~/rashomon_importance_distribution.py:479\u001b[0m, in \u001b[0;36mRashomonImportanceDistribution.mean\u001b[0;34m(self, var)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\u001b[38;5;28mself\u001b[39m, var):\n\u001b[1;32m    471\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;124;03m    Computes the mean variable importance for var\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;124;03m            evaluate the CDF\u001b[39;00m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrid_with_counts[var]\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[0;31mKeyError\u001b[0m: 13"
     ]
    }
   ],
   "source": [
    "from rashomon_importance_distribution import RashomonImportanceDistribution\n",
    "\n",
    "mapping={\n",
    "    0:[0],\n",
    "    1:[1],\n",
    "    2:[2],\n",
    "    3:[3],\n",
    "    4:[4],\n",
    "    5:[5],\n",
    "    6:[6],\n",
    "    7:[7],\n",
    "    8:[8],\n",
    "    9:[9],\n",
    "    10:[10],\n",
    "    11:[11],\n",
    "    12:[12]\n",
    "   \n",
    "}\n",
    "\n",
    "RID = RashomonImportanceDistribution(\n",
    "    input_df = df,\n",
    "    binning_map = mapping,\n",
    "    db = 5,\n",
    "    lam = 0.05,\n",
    "    eps = 0.2,\n",
    "    vi_metric = 'sub_mr',\n",
    "    dataset_name = 'binarized_data_set_all_sets_combined',\n",
    "    n_resamples = 100,\n",
    "    verbose = True,\n",
    "    max_par_for_gosdt = 4\n",
    ")\n",
    "\n",
    "for v in range(15):\n",
    "    print(f'Variable {v} ------------')\n",
    "\n",
    "    print('Box and whiskers mean:', RID.mean(v))\n",
    "    print('Box and whiskers median:', RID.median(v))\n",
    "    print('Box and whiskers range:', RID.bwr(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for v in range(14):\n",
    "    print(f'Variable {v} ------------')\n",
    "\n",
    "    print('Box and whiskers mean:', RID.mean(v))\n",
    "    print('Box and whiskers median:', RID.median(v))\n",
    "    print('Box and whiskers range:', RID.bwr(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0p-Mkr8o_tZ2"
   },
   "outputs": [],
   "source": [
    "dfr = pd.read_csv(\"binarized_heart_disease.csv\")\n",
    "\n",
    "Xr = dfr.drop(columns=['num','Blood sugar', 'Diastolic blood pressure', 'Heart rate', 'sex_Male', 'thalch', 'Troponin', 'fbs', 'CK-MB', 'thal_reversable defect', 'slope_downsloping', 'restecg_lv hypertrophy', 'dataset_VA Long Beach', 'cp_atypical angina', 'thal_fixed defect', 'restecg_normal', 'dataset_Cleveland', 'cp_typical angina', 'slope_upsloping', 'dataset_Hungary', 'slope_flat', 'sex_Female', 'exang', 'restecg_st-t abnormality'])\n",
    "yr = dfr['num']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CXN6ZmzJ_tZ2"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_trainr, X_testr, y_trainr, y_testr = train_test_split(Xr,yr,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "sBn9JGq7_tZ2",
    "outputId": "7c0fe1cf-61d2-4812-c783-f768dcc7b36e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization: 0.02; Fold 1; Train set: 188, Validation set: 21\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.012 (user, system, wall), mem=0 MB\n",
      "bounds: [0.223617..0.223617] (0.000000) loss=0.143617, iterations=1072\n",
      "Regularization: 0.02; Fold 1; Training Accuracy: 0.8563829787234043, Validation Accuracy: 0.8095238095238095, Number of Leaves: 4, Number of Nodes: 7\n",
      "\n",
      "Regularization: 0.02; Fold 2; Train set: 188, Validation set: 21\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.011 (user, system, wall), mem=0 MB\n",
      "bounds: [0.223617..0.223617] (0.000000) loss=0.143617, iterations=1019\n",
      "Regularization: 0.02; Fold 2; Training Accuracy: 0.8563829787234043, Validation Accuracy: 0.8095238095238095, Number of Leaves: 4, Number of Nodes: 7\n",
      "\n",
      "Regularization: 0.02; Fold 3; Train set: 188, Validation set: 21\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.012 (user, system, wall), mem=0 MB\n",
      "bounds: [0.239574..0.239574] (0.000000) loss=0.159574, iterations=1117\n",
      "Regularization: 0.02; Fold 3; Training Accuracy: 0.8404255319148937, Validation Accuracy: 0.9523809523809523, Number of Leaves: 4, Number of Nodes: 7\n",
      "\n",
      "Regularization: 0.02; Fold 4; Train set: 188, Validation set: 21\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.013 (user, system, wall), mem=0 MB\n",
      "bounds: [0.218298..0.218298] (0.000000) loss=0.138298, iterations=1261\n",
      "Regularization: 0.02; Fold 4; Training Accuracy: 0.8617021276595744, Validation Accuracy: 0.7619047619047619, Number of Leaves: 4, Number of Nodes: 7\n",
      "\n",
      "Regularization: 0.02; Fold 5; Train set: 188, Validation set: 21\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.011 (user, system, wall), mem=0 MB\n",
      "bounds: [0.234255..0.234255] (0.000000) loss=0.154255, iterations=1126\n",
      "Regularization: 0.02; Fold 5; Training Accuracy: 0.8457446808510638, Validation Accuracy: 0.9047619047619048, Number of Leaves: 4, Number of Nodes: 7\n",
      "\n",
      "Regularization: 0.02; Fold 6; Train set: 188, Validation set: 21\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.012 (user, system, wall), mem=0 MB\n",
      "bounds: [0.228936..0.228936] (0.000000) loss=0.148936, iterations=1182\n",
      "Regularization: 0.02; Fold 6; Training Accuracy: 0.851063829787234, Validation Accuracy: 0.8571428571428571, Number of Leaves: 4, Number of Nodes: 7\n",
      "\n",
      "Regularization: 0.02; Fold 7; Train set: 188, Validation set: 21\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.012 (user, system, wall), mem=0 MB\n",
      "bounds: [0.212979..0.212979] (0.000000) loss=0.132979, iterations=1190\n",
      "Regularization: 0.02; Fold 7; Training Accuracy: 0.8670212765957447, Validation Accuracy: 0.7142857142857143, Number of Leaves: 4, Number of Nodes: 7\n",
      "\n",
      "Regularization: 0.02; Fold 8; Train set: 188, Validation set: 21\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.013 (user, system, wall), mem=0 MB\n",
      "bounds: [0.244894..0.244894] (0.000000) loss=0.164894, iterations=1221\n",
      "Regularization: 0.02; Fold 8; Training Accuracy: 0.8351063829787234, Validation Accuracy: 1.0, Number of Leaves: 4, Number of Nodes: 7\n",
      "\n",
      "Regularization: 0.02; Fold 9; Train set: 188, Validation set: 21\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.013 (user, system, wall), mem=0 MB\n",
      "bounds: [0.228936..0.228936] (0.000000) loss=0.148936, iterations=1289\n",
      "Regularization: 0.02; Fold 9; Training Accuracy: 0.851063829787234, Validation Accuracy: 0.8571428571428571, Number of Leaves: 4, Number of Nodes: 7\n",
      "\n",
      "Regularization: 0.02; Fold 10; Train set: 189, Validation set: 20\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.012 (user, system, wall), mem=0 MB\n",
      "bounds: [0.228148..0.228148] (0.000000) loss=0.148148, iterations=1213\n",
      "Regularization: 0.02; Fold 10; Training Accuracy: 0.8518518518518519, Validation Accuracy: 0.85, Number of Leaves: 4, Number of Nodes: 7\n",
      "\n",
      "Mean Validation Accuracy across folds: 0.8516666666666666----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--- Final Results ---\n",
      "Final Test Accuracy: 0.7333\n",
      "Test Precision (macro): 0.7928\n",
      "Test Recall (macro): 0.7173\n",
      "Confusion Matrix:\n",
      "[[23  1]\n",
      " [11 10]]\n",
      "\n",
      "--- Summary of Train and Validation Metrics ---\n",
      "Training Accuracy: 0.8517\n",
      "Training Precision (macro): 0.8634\n",
      "Training Recall (macro): 0.8450\n",
      "Validation Accuracy: 0.8517\n",
      "Validation Precision (macro): 0.8770\n",
      "Validation Recall (macro): 0.8458\n",
      "# of leaves: 4\n",
      "# of nodes: 7\n",
      "Confusion Matrix: \n",
      "<bound method GOSDT.confusion of <gosdt.model.gosdt.GOSDT object at 0x7f46137eaa10>>\n",
      "Tree structure: \n",
      "if ca = 1 and cp_asymptomatic = 1 then:\n",
      "    predicted class: 1\n",
      "    misclassification penalty: 0.011\n",
      "    complexity penalty: 0.02\n",
      "\n",
      "else if ca != 1 and cp_asymptomatic = 1 and thal_normal = 1 then:\n",
      "    predicted class: 0\n",
      "    misclassification penalty: 0.016\n",
      "    complexity penalty: 0.02\n",
      "\n",
      "else if ca != 1 and cp_asymptomatic = 1 and thal_normal != 1 then:\n",
      "    predicted class: 1\n",
      "    misclassification penalty: 0.027\n",
      "    complexity penalty: 0.02\n",
      "\n",
      "else if cp_asymptomatic != 1 then:\n",
      "    predicted class: 0\n",
      "    misclassification penalty: 0.112\n",
      "    complexity penalty: 0.02\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import gosdt\n",
    "\n",
    "# Step 1: Split the dataset into training, validation, and test sets\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(Xr, yr, test_size=0.15, random_state=42, stratify=yr)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.15/.85, random_state=42, stratify=y_temp)\n",
    "\n",
    "# Stratified K-fold Cross-validation\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Regularization values to test\n",
    "regularization = [0.02]\n",
    "\n",
    "# DataFrame to store results\n",
    "hp_gridr = pd.DataFrame(columns=['regularization', 'average_test_accuracy'])\n",
    "\n",
    "# Initialize variables for tracking the best model and metrics\n",
    "best_model = None\n",
    "best_val_acc = 0\n",
    "all_train_acc = []\n",
    "all_train_precision = []\n",
    "all_train_recall = []\n",
    "all_val_acc = []\n",
    "all_val_precision = []\n",
    "all_val_recall = []\n",
    "\n",
    "# Iterate over each regularization value\n",
    "for reg in regularization:\n",
    "    cnt = 1\n",
    "    test_accuracyr = []\n",
    "\n",
    "    # Cross-validation loop\n",
    "    for train_indexr, val_indexr in kf.split(X_train, y_train):\n",
    "        print(f'Regularization: {reg}; Fold {cnt}; Train set: {len(train_indexr)}, Validation set: {len(val_indexr)}')\n",
    "\n",
    "        # Create training and validation sets for the current fold\n",
    "        kfX_trainr = X_train.iloc[train_indexr, :]\n",
    "        kfX_valr = X_train.iloc[val_indexr, :]\n",
    "        kfy_trainr = y_train.iloc[train_indexr]\n",
    "        kfy_valr = y_train.iloc[val_indexr]\n",
    "\n",
    "        # Configuration for the GOSDT model\n",
    "        config = {\n",
    "            \"regularization\": reg,\n",
    "            \"depth_budget\": 5\n",
    "        }\n",
    "\n",
    "        # Instantiate and train the model\n",
    "        model = gosdt.GOSDT(config)\n",
    "        model.fit(kfX_trainr, kfy_trainr)\n",
    "\n",
    "        # Calculate training and validation accuracies\n",
    "        train_accr = model.score(kfX_trainr, kfy_trainr)\n",
    "        val_accr = model.score(kfX_valr, kfy_valr)\n",
    "        n_leavesr = model.leaves()\n",
    "        n_nodesr = model.nodes()\n",
    "\n",
    "        # Track the best model based on validation accuracy\n",
    "        if val_accr > best_val_acc:\n",
    "            best_val_acc = val_accr\n",
    "            best_model = model\n",
    "\n",
    "        # Collect metrics for later reporting\n",
    "        all_train_acc.append(train_accr)\n",
    "        all_train_precision.append(precision_score(kfy_trainr, model.predict(kfX_trainr), average='macro'))\n",
    "        all_train_recall.append(recall_score(kfy_trainr, model.predict(kfX_trainr), average='macro'))\n",
    "\n",
    "        all_val_acc.append(val_accr)\n",
    "        all_val_precision.append(precision_score(kfy_valr, model.predict(kfX_valr), average='macro'))\n",
    "        all_val_recall.append(recall_score(kfy_valr, model.predict(kfX_valr), average='macro'))\n",
    "\n",
    "        # Store the result for the current regularization\n",
    "        test_accuracyr.append(val_accr)\n",
    "        print(f'Regularization: {reg}; Fold {cnt}; Training Accuracy: {train_accr}, Validation Accuracy: {val_accr}, '\n",
    "              f'Number of Leaves: {n_leavesr}, Number of Nodes: {n_nodesr}\\n')\n",
    "\n",
    "        cnt += 1\n",
    "\n",
    "    # Calculate mean validation accuracy across folds\n",
    "    mean_val_accr = sum(test_accuracyr) / len(test_accuracyr)\n",
    "    print(f'Mean Validation Accuracy across folds: {mean_val_accr}----------------------------------------------------------------------\\n')\n",
    "\n",
    "    # Store the result for the current regularization\n",
    "    hp_gridr = pd.concat([hp_gridr, pd.DataFrame([[reg, mean_val_accr]], columns=hp_gridr.columns)], ignore_index=True)\n",
    "\n",
    "# If the best model is found, evaluate it on the test set\n",
    "if best_model is not None:\n",
    "    # Get predictions on the test set\n",
    "    test_preds = best_model.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy, precision, recall, and confusion matrix on the test set\n",
    "    test_acc = best_model.score(X_test, y_test)\n",
    "    test_precision = precision_score(y_test, test_preds, average='macro')\n",
    "    test_recall = recall_score(y_test, test_preds, average='macro')\n",
    "    cm = confusion_matrix(y_test, test_preds)\n",
    "\n",
    "    # Print final results\n",
    "    print(\"\\n--- Final Results ---\")\n",
    "    print(f'Final Test Accuracy: {test_acc:.4f}')\n",
    "    print(f'Test Precision (macro): {test_precision:.4f}')\n",
    "    print(f'Test Recall (macro): {test_recall:.4f}')\n",
    "    print(f'Confusion Matrix:\\n{cm}')\n",
    "\n",
    "    # Print training and validation metrics\n",
    "    print(\"\\n--- Summary of Train and Validation Metrics ---\")\n",
    "    print(f\"Training Accuracy: {sum(all_train_acc) / len(all_train_acc):.4f}\")\n",
    "    print(f\"Training Precision (macro): {sum(all_train_precision) / len(all_train_precision):.4f}\")\n",
    "    print(f\"Training Recall (macro): {sum(all_train_recall) / len(all_train_recall):.4f}\")\n",
    "    \n",
    "    print(f\"Validation Accuracy: {sum(all_val_acc) / len(all_val_acc):.4f}\")\n",
    "    print(f\"Validation Precision (macro): {sum(all_val_precision) / len(all_val_precision):.4f}\")\n",
    "    print(f\"Validation Recall (macro): {sum(all_val_recall) / len(all_val_recall):.4f}\")\n",
    "\n",
    "    # Print model details\n",
    "    print(f\"# of leaves: {best_model.leaves()}\")\n",
    "    print(f\"# of nodes: {best_model.nodes()}\")\n",
    "    print(f\"Confusion Matrix: \\n{best_model.confusion}\")\n",
    "    print(f\"Tree structure: \\n{best_model.tree}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "VVtZnS70_tZ3",
    "outputId": "01ff3061-1079-42f6-8a65-5de3ce6eff4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regularization           0.020000\n",
      "average_test_accuracy    0.851667\n",
      "dtype: float64\n",
      "   regularization  average_test_accuracy\n",
      "0            0.02               0.851667\n"
     ]
    }
   ],
   "source": [
    "print(hp_gridr.max())\n",
    "print(hp_gridr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UcSXlQsD_tZ3",
    "outputId": "0ca2ccd2-b713-423d-e35e-750be6fa2f4a"
   },
   "outputs": [],
   "source": [
    "import gosdt\n",
    "\n",
    "config = {\n",
    "            \"regularization\": 0.002,\n",
    "            \"depth_budget\": 0\n",
    "        }\n",
    "model = gosdt.GOSDT(config)\n",
    "model.fit(X_trainr, y_trainr)\n",
    "\n",
    "train_accr = model.score(X_trainr, y_trainr)\n",
    "test_accr = model.score(X_testr, y_testr)\n",
    "n_leavesr = model.leaves()\n",
    "n_nodesr = model.nodes()\n",
    "\n",
    "print(f'Training Accuracy: {train_accr}, Test Accuracy: {test_accr}, Number of Leaves: {n_leavesr}, Number of Nodes: {n_nodesr}\\n')\n",
    "print(model.tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6CxFDut1_tZ3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dimacs2024",
   "language": "python",
   "name": "dimacs2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
